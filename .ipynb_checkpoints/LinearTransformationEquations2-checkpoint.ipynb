{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58417a24-7252-4a8c-a321-2de2198181d1",
   "metadata": {},
   "source": [
    "# Linear transformations and equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa0539-401a-4c34-b83b-c6394dd52302",
   "metadata": {},
   "source": [
    "These equations and transformations play crucial roles in various aspects of drug discovery, from data preprocessing and feature extraction to similarity measurement and statistical analysis. They provide different ways to represent, compare, and analyze the complex data encountered in these fields."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38e804b7-cb20-4404-bd26-57c5d50d773c",
   "metadata": {},
   "source": [
    "\n",
    "## Instances where we use the Partial Least Squares (PLS) Regression: Equation: Y = XB + E\n",
    "PLS Regression is particularly useful in these contexts because it can handle high-dimensional data with correlated features, which is common in biological and chemical datasets. It performs dimensionality reduction and regression simultaneously, making it efficient for modeling complex relationships in biomolecular data.\n",
    "\n",
    "These examples demonstrate the versatility and importance of PLS Regression in various aspects of drug discovery:\n",
    "\n",
    "* **QSAR modeling** for predicting molecular activity\n",
    "* **Protein-ligand binding affinity prediction**\n",
    "* **Protein structure quality assessment**\n",
    "* **Drug solubility prediction**\n",
    "* **Protein-protein interaction prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc02d0-aec1-43b0-825f-08455c0a6caf",
   "metadata": {},
   "source": [
    "### QSAR (Quantitative Structure-Activity Relationship) Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4f2c7-6552-43c1-b409-65eae5a5b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 100, 50\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_B = np.random.randn(n_features, 1)\n",
    "Y = X.dot(true_B) + np.random.randn(n_samples, 1) * 0.1\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PLS regression\n",
    "pls = PLSRegression(n_components=5)\n",
    "pls.fit(X_train, Y_train)\n",
    "\n",
    "# Predictions\n",
    "Y_pred = pls.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f\"R-squared score: {r2:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Activity\")\n",
    "plt.ylabel(\"Predicted Activity\")\n",
    "plt.title(\"QSAR Model using PLS Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121d791-a945-47bf-bebf-aef6a05fc407",
   "metadata": {},
   "source": [
    "### Protein-Ligand Binding Affinity Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca1bcd-a1b1-4209-b438-292ca6778625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_protein_features, n_ligand_features = 200, 30, 20\n",
    "X_protein = np.random.randn(n_samples, n_protein_features)\n",
    "X_ligand = np.random.randn(n_samples, n_ligand_features)\n",
    "X = np.hstack((X_protein, X_ligand))\n",
    "Y = np.sum(X, axis=1) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "# PLS regression with cross-validation\n",
    "pls = PLSRegression(n_components=10)\n",
    "cv_scores = cross_val_score(pls, X, Y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Plot MSE vs number of components\n",
    "n_components_range = range(1, 21)\n",
    "mse_scores = []\n",
    "for n_components in n_components_range:\n",
    "    pls = PLSRegression(n_components=n_components)\n",
    "    scores = cross_val_score(pls, X, Y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores.append(-scores.mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components_range, mse_scores, marker='o')\n",
    "plt.xlabel(\"Number of PLS Components\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.title(\"PLS Components vs MSE in Binding Affinity Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd1e1f-3a6a-4cb9-a9cd-688711499002",
   "metadata": {},
   "source": [
    "### Protein Structure Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389c572-8ac6-4aa3-af30-e392022fcbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 150, 40\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "Y = np.sum(X[:, :10], axis=1) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PLS regression\n",
    "pls = PLSRegression(n_components=5)\n",
    "pls.fit(X_train, Y_train)\n",
    "\n",
    "# Predictions\n",
    "Y_pred = pls.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importance = np.sum(np.abs(pls.coef_), axis=0)\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, sorted_idx)\n",
    "plt.xlabel('Absolute Importance')\n",
    "plt.ylabel('Feature Index')\n",
    "plt.title('Feature Importance in Protein Structure Quality Assessment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3b1f5-f3ae-4f52-b236-c50110ac48a4",
   "metadata": {},
   "source": [
    "### Drug Solubility Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f062f55-89d8-43a4-93f7-82cc6c6c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 300, 25\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "Y = np.exp(np.sum(X[:, :5], axis=1)) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "# PLS regression\n",
    "pls = PLSRegression(n_components=10)\n",
    "\n",
    "# Learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    pls, X, Y, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.title(\"Learning Curve for Drug Solubility Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15863c8-387b-40ce-9ce1-b9214244a963",
   "metadata": {},
   "source": [
    "### Protein-Protein Interaction Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bcdb1-50b3-4441-a379-dc75492becfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 500, 60\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "Y = (np.sum(X[:, :10], axis=1) > 0).astype(int)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# PLS regression\n",
    "pls = PLSRegression(n_components=15)\n",
    "pls.fit(X_train, Y_train)\n",
    "\n",
    "# Predictions\n",
    "Y_pred = pls.predict(X_test)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Protein-Protein Interaction Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47989a-26db-43f1-b287-36f3cbb8639c",
   "metadata": {},
   "source": [
    "## Instances where we use the Linear Discriminant Analysis (LDA): Equation: y = w^T x + w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115b38e-b801-4d18-8f4d-e6e656410ba8",
   "metadata": {},
   "source": [
    "* **Protein Structure Classification**:  This snippet uses LDA to classify protein structures into alpha helices and beta sheets based on their features. It showcases LDA's ability to find the optimal linear combination of features that separates different structural classes.\n",
    "\n",
    "* **Drug Activity Classification**:  This example demonstrates how LDA can be used to classify drugs as active or inactive based on their molecular properties. It uses cross-validation to assess the model's performance and visualizes the results with a confusion matrix.\n",
    "\n",
    "* **Protein-Ligand Binding Site Prediction**:  This snippet uses LDA to predict protein-ligand binding sites. It demonstrates how LDA can be used for binary classification tasks in structural biology and visualizes the model's performance using a ROC curve.\n",
    "\n",
    "* **Protein Solubility Prediction**:  This example applies LDA to predict protein solubility. It generates a learning curve to show how the model's performance changes with increasing training data, which is useful for understanding the model's behavior and potential overfitting.\n",
    "\n",
    "* **Drug Target Classification**:  This snippet uses LDA for multi-class classification of drug targets. It demonstrates LDA's capability to handle multiple classes, which is often necessary in drug discovery when dealing with different types of drug targets. The classification report provides detailed performance metrics, and the visualization shows how LDA projects the data onto a 2D space for separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2069d6-18d0-408d-a69f-a3039046743b",
   "metadata": {},
   "source": [
    "### Protein Structure Classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc778508-e924-446a-a418-81931a8c5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "n_features = 10\n",
    "\n",
    "# Class 0: Alpha helices, Class 1: Beta sheets\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = (np.sum(X[:, :3], axis=1) > 0).astype(int)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = lda.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Visualize LDA projection\n",
    "X_lda = lda.transform(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_lda[y==0], np.zeros(sum(y==0)), c='r', label='Alpha helices')\n",
    "plt.scatter(X_lda[y==1], np.zeros(sum(y==1)), c='b', label='Beta sheets')\n",
    "plt.legend()\n",
    "plt.title(\"LDA Projection of Protein Structures\")\n",
    "plt.xlabel(\"LDA Component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0563fd9-1624-4a7b-a381-88fd84efe203",
   "metadata": {},
   "source": [
    "### Drug Activity Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe54c6-3f85-4cbd-8d0f-ca1719a6a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "n_features = 5\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = (np.sum(X, axis=1) > 0).astype(int)  # 0: Inactive, 1: Active\n",
    "\n",
    "# Apply LDA with cross-validation\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "cv_scores = cross_val_score(lda, X, y, cv=5)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Fit LDA and get confusion matrix\n",
    "lda.fit(X, y)\n",
    "y_pred = lda.predict(X)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Inactive', 'Active'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for Drug Activity Classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e7fc8-09fa-4a1b-b6bd-18845e0d230f",
   "metadata": {},
   "source": [
    "### Protein-Ligand Binding Site Prediction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b3651-a267-4b96-9792-b7bf1a70a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "n_features = 8\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = (np.sum(X[:, :4], axis=1) > 0).astype(int)  # 0: Non-binding, 1: Binding\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = lda.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Protein-Ligand Binding Site Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f89e50-a244-47e7-b839-7acc2b989571",
   "metadata": {},
   "source": [
    "### Protein Solubility Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17c0a6-bf91-4e11-a0cb-394cda48984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "n_features = 6\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = (np.sum(X, axis=1) > 0).astype(int)  # 0: Insoluble, 1: Soluble\n",
    "\n",
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Generate learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    lda, X, y, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Learning Curve for Protein Solubility Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56938b0-71b2-4fb0-9532-79a60716d9f4",
   "metadata": {},
   "source": [
    "### Drug Target Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fd73d-eee0-4954-90b7-1cb3c5f44337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 400\n",
    "n_features = 10\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.argmax(X[:, :3], axis=1)  # 3 classes of drug targets\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1', 'Class 2']))\n",
    "\n",
    "# Visualize LDA projection\n",
    "X_lda = lda.transform(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['r', 'g', 'b']\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], ['Class 0', 'Class 1', 'Class 2']):\n",
    "    plt.scatter(X_lda[y == i, 0], X_lda[y == i, 1], alpha=.8, color=color, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of Drug Target Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db2a43-b4ef-47a1-a5bb-0b0da0409d4c",
   "metadata": {},
   "source": [
    "## Instances where we use the Mahalanobis Distance Equation: D^2 = (x - μ)^T S^-1 (x - μ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f67ff-e5e9-47aa-ad15-e25d2ddcb075",
   "metadata": {},
   "source": [
    "* **Outlier Detection in Protein Structure Data:**:  This snippet uses Mahalanobis Distance to detect outliers in protein structure data. It's useful for identifying unusual protein conformations or potential errors in structural data.\n",
    "\n",
    "* **Drug-likeness Assessment:**:  This example uses Mahalanobis Distance to assess the \"drug-likeness\" of compounds based on their molecular properties. It helps in filtering out compounds that are unlikely to be good drug candidates.\n",
    "\n",
    "* **Protein-Ligand Binding Site Similarity:**:  This snippet uses Mahalanobis Distance to measure the similarity between protein-ligand binding sites. It's useful for identifying proteins with similar binding sites, which could potentially bind similar ligands.\n",
    "\n",
    "* **Quality Control in High-Throughput Screening:**:  This example uses Mahalanobis Distance for quality control in high-throughput screening data. It helps identify potentially erroneous measurements or compounds with unusual behavior.\n",
    "\n",
    "* **Protein Structure Comparison:**:  This snippet uses Mahalanobis Distance to compare protein structures. It's useful for identifying structures similar to a reference structure, which can be important in understanding protein function or drug interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1171f-be09-448c-8c80-d9356c9f5773",
   "metadata": {},
   "source": [
    "### Outlier Detection in Protein Structure Data::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493429c5-e796-4bd9-9b3b-b0e1dbb94149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "# Generate synthetic protein structure data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 1000, 2\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Add some outliers\n",
    "X[:10] += np.array([10, 10])\n",
    "\n",
    "# Fit a Gaussian distribution to the data\n",
    "cov = EmpiricalCovariance().fit(X)\n",
    "\n",
    "# Compute Mahalanobis distances\n",
    "m_dist = cov.mahalanobis(X)\n",
    "\n",
    "# Determine threshold (95% of the data should be inliers)\n",
    "threshold = chi2.ppf((1 - 0.05), df=n_features)\n",
    "\n",
    "# Create a grid for contour plotting\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Compute Mahalanobis distances for the grid\n",
    "grid_m_dist = cov.mahalanobis(grid_points)\n",
    "grid_m_dist = grid_m_dist.reshape(xx.shape)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot data points\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=m_dist, cmap='viridis', edgecolor='black')\n",
    "plt.colorbar(scatter, label='Mahalanobis Distance')\n",
    "\n",
    "# Plot contours\n",
    "levels = [chi2.ppf((1 - alpha), df=n_features) for alpha in [0.05, 0.01, 0.001]]\n",
    "contour = plt.contour(xx, yy, grid_m_dist, levels=levels, colors=['r', 'g', 'b'], linestyles='dashed')\n",
    "plt.clabel(contour, inline=1, fontsize=10, fmt={levels[0]: '95%', levels[1]: '99%', levels[2]: '99.9%'})\n",
    "\n",
    "plt.title('Outlier Detection in Protein Structure Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of outliers detected (95% threshold): {np.sum(m_dist > threshold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d125403-0e9c-46a3-acad-304c751bc0a4",
   "metadata": {},
   "source": [
    "### Drug-likeness Assessment::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690e878-9b62-4c6e-a394-ef3577710b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "# Generate synthetic drug property data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "molecular_weight = np.random.normal(300, 50, n_samples)\n",
    "logP = np.random.normal(2, 1, n_samples)\n",
    "hydrogen_bond_donors = np.random.poisson(2, n_samples)\n",
    "hydrogen_bond_acceptors = np.random.poisson(5, n_samples)\n",
    "\n",
    "X = np.column_stack([molecular_weight, logP, hydrogen_bond_donors, hydrogen_bond_acceptors])\n",
    "\n",
    "# Fit a Gaussian distribution to the data\n",
    "cov = EmpiricalCovariance().fit(X)\n",
    "\n",
    "# Compute Mahalanobis distances\n",
    "m_dist = cov.mahalanobis(X)\n",
    "\n",
    "# Determine threshold (90% of the data should be considered drug-like)\n",
    "threshold = chi2.ppf((1 - 0.1), df=X.shape[1])\n",
    "\n",
    "# Create a DataFrame with results\n",
    "df = pd.DataFrame({\n",
    "    'Molecular Weight': molecular_weight,\n",
    "    'LogP': logP,\n",
    "    'H-Bond Donors': hydrogen_bond_donors,\n",
    "    'H-Bond Acceptors': hydrogen_bond_acceptors,\n",
    "    'Mahalanobis Distance': m_dist,\n",
    "    'Drug-like': m_dist <= threshold\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "print(f\"\\nPercentage of drug-like compounds: {100 * df['Drug-like'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7248c3a-07f7-46f8-9f92-f6b5c223cda4",
   "metadata": {},
   "source": [
    "### Protein-Ligand Binding Site Similarity:: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba770f-e4f1-489b-b0d9-723c0c567c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "# Generate synthetic binding site data\n",
    "np.random.seed(42)\n",
    "n_sites = 100\n",
    "n_features = 5\n",
    "\n",
    "reference_site = np.random.randn(n_features)\n",
    "binding_sites = np.random.randn(n_sites, n_features)\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov = EmpiricalCovariance().fit(binding_sites)\n",
    "\n",
    "# Compute Mahalanobis distances\n",
    "m_distances = np.array([mahalanobis(site, reference_site, cov.precision_) \n",
    "                        for site in binding_sites])\n",
    "\n",
    "# Plot histogram of distances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(m_distances, bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Binding Site Similarities')\n",
    "plt.xlabel('Mahalanobis Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Find most similar binding sites\n",
    "most_similar = np.argsort(m_distances)[:5]\n",
    "print(\"Indices of 5 most similar binding sites:\", most_similar)\n",
    "print(\"Their distances:\", m_distances[most_similar])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b8b4e-a5ff-4c09-8510-81bc2e386b53",
   "metadata": {},
   "source": [
    "### Quality Control in High-Throughput Screening::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1cf75-fcd0-4744-bb42-28209eb0d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "from sklearn.covariance import MinCovDet\n",
    "\n",
    "# Generate synthetic screening data\n",
    "np.random.seed(42)\n",
    "n_compounds = 1000\n",
    "n_features = 3\n",
    "\n",
    "X = np.random.randn(n_compounds, n_features)\n",
    "\n",
    "# Add some outliers (potentially erroneous measurements)\n",
    "X[:20] += np.array([5, 5, 5])\n",
    "\n",
    "# Use Minimum Covariance Determinant for robust estimation\n",
    "robust_cov = MinCovDet().fit(X)\n",
    "\n",
    "# Compute Mahalanobis distances\n",
    "m_distances = robust_cov.mahalanobis(X)\n",
    "\n",
    "# Determine threshold (99% of the data should be considered normal)\n",
    "threshold = chi2.ppf((1 - 0.01), df=n_features)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(n_compounds), m_distances, c=m_distances, cmap='viridis')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.colorbar(label='Mahalanobis Distance')\n",
    "plt.title('Quality Control in High-Throughput Screening')\n",
    "plt.xlabel('Compound Index')\n",
    "plt.ylabel('Mahalanobis Distance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of potential errors detected: {np.sum(m_distances > threshold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a94b3-7107-4cf5-acd4-d5b8999e0052",
   "metadata": {},
   "source": [
    "### Protein Structure Comparison::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdf7aa-4342-4439-97f2-b8829f7c71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Generate synthetic protein structure data\n",
    "np.random.seed(42)\n",
    "n_structures = 200\n",
    "n_features = 10\n",
    "\n",
    "reference_structure = np.random.randn(n_features)\n",
    "structures = np.random.randn(n_structures, n_features)\n",
    "\n",
    "# Add some similar structures\n",
    "structures[:20] = reference_structure + np.random.randn(20, n_features) * 0.1\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov = EmpiricalCovariance().fit(structures)\n",
    "\n",
    "# Compute Mahalanobis distances\n",
    "m_distances = np.array([mahalanobis(structure, reference_structure, cov.precision_) \n",
    "                        for structure in structures])\n",
    "\n",
    "# Perform PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "structures_2d = pca.fit_transform(structures)\n",
    "reference_2d = pca.transform([reference_structure])[0]\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(structures_2d[:, 0], structures_2d[:, 1], c=m_distances, cmap='viridis')\n",
    "plt.colorbar(scatter, label='Mahalanobis Distance')\n",
    "plt.scatter(reference_2d[0], reference_2d[1], c='r', s=100, marker='*', label='Reference')\n",
    "plt.title('Protein Structure Comparison')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Structures most similar to the reference:\")\n",
    "most_similar = np.argsort(m_distances)[:5]\n",
    "print(\"Indices:\", most_similar)\n",
    "print(\"Distances:\", m_distances[most_similar])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642c469-5070-4763-a8a0-ada9edf8e48f",
   "metadata": {},
   "source": [
    "## Instances where we use the Discrete Fourier Transform (DFT) Equation: X_k = Σ(n=0 to N-1) x_n · e^(-2πi k n / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa1619-383f-4ba4-8b7f-696f5ae98eda",
   "metadata": {},
   "source": [
    "* **Protein Secondary Structure Analysis:**  This snippet uses DFT to analyze the hydrophobicity pattern of a protein sequence. It can help identify periodic structures like alpha-helices, which typically have a periodicity of 3.6 residues.\n",
    "\n",
    "* **Drug-Target Interaction Prediction**:  This example uses DFT to extract features from molecular SMILES representations for predicting drug-target interactions. The DFT helps capture periodic patterns in the molecular structure.\n",
    "\n",
    "* **Protein Disorder Prediction**:  This snippet uses DFT to extract features from protein charge patterns for predicting protein disorder. The DFT can capture long-range charge interactions that are often associated with disordered regions.\n",
    "\n",
    "* **Drug Solubility Prediction**:  This example uses DFT to extract features from molecular SMILES representations for predicting drug solubility. The DFT can capture periodic patterns in the molecular structure that may be relevant to solubility.\n",
    "\n",
    "* **Protein-Protein Interaction Site Prediction:**:  This snippet uses DFT to extract features from protein hydrophobicity patterns for predicting protein-protein interaction sites. The DFT can capture periodic hydrophobicity patterns that may be indicative of interaction sites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969646f-5612-4c73-b24c-87aa968720f1",
   "metadata": {},
   "source": [
    "Protein Secondary Structure Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c554f74-e88d-4828-b988-2805819a082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hydrophobicity_to_signal(sequence):\n",
    "    hydrophobicity_scale = {'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "                            'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "                            'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "                            'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2}\n",
    "    return np.array([hydrophobicity_scale[aa] for aa in sequence])\n",
    "\n",
    "# Example protein sequence\n",
    "sequence = \"MKWVTFISLLLLFSSAYSRGVFRRDAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKS\"\n",
    "\n",
    "# Convert to hydrophobicity signal\n",
    "signal = hydrophobicity_to_signal(sequence)\n",
    "\n",
    "# Perform DFT\n",
    "dft = np.fft.fft(signal)\n",
    "freqs = np.fft.fftfreq(len(signal))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(freqs, np.abs(dft))\n",
    "plt.title(\"DFT of Protein Hydrophobicity Signal\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.xlim(0, 0.5)  # Show only positive frequencies up to Nyquist frequency\n",
    "plt.show()\n",
    "\n",
    "# Check for alpha-helix periodicity (around 3.6 residues)\n",
    "alpha_helix_freq = 1 / 3.6\n",
    "alpha_helix_magnitude = np.abs(dft[np.argmin(np.abs(freqs - alpha_helix_freq))])\n",
    "print(f\"Magnitude at alpha-helix frequency: {alpha_helix_magnitude:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8b145-86d0-46fa-b5fd-aec8f88c316c",
   "metadata": {},
   "source": [
    "Drug-Target Interaction Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34f96b-a3cc-4c23-bdea-0ebe19220792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def encode_molecule(smiles, max_length=100):\n",
    "    encoding = {'C': 1, 'N': 2, 'O': 3, 'S': 4, 'F': 5, 'P': 6}\n",
    "    encoded = np.zeros(max_length)\n",
    "    for i, char in enumerate(smiles[:max_length]):\n",
    "        encoded[i] = encoding.get(char, 0)\n",
    "    return encoded\n",
    "\n",
    "def dft_features(signal, n_features=10):\n",
    "    dft = np.fft.fft(signal)\n",
    "    return np.abs(dft[:n_features])\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "smiles_data = [''.join(np.random.choice(['C', 'N', 'O', 'S', 'F', 'P'], size=50)) for _ in range(n_samples)]\n",
    "interactions = np.random.randint(2, size=n_samples)\n",
    "\n",
    "# Prepare features using DFT\n",
    "X = np.array([dft_features(encode_molecule(smiles)) for smiles in smiles_data])\n",
    "y = interactions\n",
    "\n",
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccc21a-62d0-468d-b60f-2918c23de53a",
   "metadata": {},
   "source": [
    "Protein Disorder Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80258e0b-0a60-427e-8324-1edc44e52143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def charge_to_signal(sequence):\n",
    "    charge_scale = {'R': 1, 'K': 1, 'D': -1, 'E': -1}\n",
    "    return np.array([charge_scale.get(aa, 0) for aa in sequence])\n",
    "\n",
    "def dft_features(signal, n_features=20):\n",
    "    dft = np.fft.fft(signal)\n",
    "    return np.abs(dft[:n_features])\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "sequences = [''.join(np.random.choice(['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V'], size=100)) for _ in range(n_samples)]\n",
    "disorder = np.random.randint(2, size=n_samples)\n",
    "\n",
    "# Prepare features using DFT\n",
    "X = np.array([dft_features(charge_to_signal(seq)) for seq in sequences])\n",
    "y = disorder\n",
    "\n",
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Protein Disorder Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16591f0d-b18c-43df-9ba6-ea58bf82be73",
   "metadata": {},
   "source": [
    "Drug Solubility Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25651d91-5fc4-4862-9539-ef5701afb265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def encode_molecule(smiles, max_length=100):\n",
    "    encoding = {'C': 1, 'N': 2, 'O': 3, 'S': 4, 'F': 5, 'P': 6}\n",
    "    encoded = np.zeros(max_length)\n",
    "    for i, char in enumerate(smiles[:max_length]):\n",
    "        encoded[i] = encoding.get(char, 0)\n",
    "    return encoded\n",
    "\n",
    "def dft_features(signal, n_features=20):\n",
    "    dft = np.fft.fft(signal)\n",
    "    return np.abs(dft[:n_features])\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "smiles_data = [''.join(np.random.choice(['C', 'N', 'O', 'S', 'F', 'P'], size=50)) for _ in range(n_samples)]\n",
    "solubility = np.random.rand(n_samples) * 10 - 5  # Log solubility between -5 and 5\n",
    "\n",
    "# Prepare features using DFT\n",
    "X = np.array([dft_features(encode_molecule(smiles)) for smiles in smiles_data])\n",
    "y = solubility\n",
    "\n",
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([-5, 5], [-5, 5], 'r--')\n",
    "plt.xlabel(\"Actual Log Solubility\")\n",
    "plt.ylabel(\"Predicted Log Solubility\")\n",
    "plt.title(\"Drug Solubility Prediction using DFT Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162ad97-5120-494f-8b40-7948744d1bf5",
   "metadata": {},
   "source": [
    "Protein-Protein Interaction Site Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ea333-50a3-4ca3-9e6b-4d3bd566eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hydrophobicity_to_signal(sequence):\n",
    "    hydrophobicity_scale = {'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "                            'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "                            'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "                            'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2}\n",
    "    return np.array([hydrophobicity_scale[aa] for aa in sequence])\n",
    "\n",
    "def dft_features(signal, n_features=20):\n",
    "    dft = np.fft.fft(signal)\n",
    "    return np.abs(dft[:n_features])\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "sequences = [''.join(np.random.choice(['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V'], size=100)) for _ in range(n_samples)]\n",
    "interaction_sites = np.random.randint(2, size=n_samples)\n",
    "\n",
    "# Prepare features using DFT\n",
    "X = np.array([dft_features(hydrophobicity_to_signal(seq)) for seq in sequences])\n",
    "y = interaction_sites\n",
    "\n",
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = MLPClassifier(hidden_layer_sizes=(50, 25), random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance = np.mean(np.abs(model.coefs_[0]), axis=0)\n",
    "plt.bar(range(len(feature_importance)), feature_importance)\n",
    "plt.xlabel(\"DFT Feature Index\")\n",
    "plt.ylabel(\"Average Absolute Weight\")\n",
    "plt.title(\"Importance of DFT Features in Protein-Protein Interaction Site Prediction\")\n",
    "plt.show()\n",
    "\n",
    "# Plot first few DFT features for some samples\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    plt.plot(X[i, :10], label=f'Sample {i+1}')\n",
    "plt.xlabel(\"DFT Feature Index\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"First 10 DFT Features for 5 Samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9f652-9777-493f-8380-66144c507613",
   "metadata": {},
   "source": [
    "## Instances where we use the Tanimoto Coefficient (for binary data) Equation: T(A,B) = (A · B) / (|A|^2 + |B|^2 - A · B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15becf2-99f8-4bbe-8672-8ae5a79a0851",
   "metadata": {},
   "source": [
    "* **Molecular Similarity in Drug Discovery:**  This snippet calculates and visualizes the Tanimoto similarity between a reference drug (Aspirin) and potential drug candidates. It's useful in drug discovery for identifying structurally similar compounds that might have similar properties or effects.\n",
    "\n",
    "* **Protein Sequence Similarity Analysis:**  This example calculates and visualizes the Tanimoto similarities between different protein sequences. It's useful for comparing protein sequences and identifying potentially related proteins.\n",
    "\n",
    "* **Virtual Screening for Drug Discovery**:  This snippet performs a virtual screening by comparing a target protein binding site to a library of compounds using Tanimoto similarity. It's useful in drug discovery for identifying potential drug candidates that might bind to a specific target.\n",
    "\n",
    "* **Protein Family Classification**:  This example uses the Tanimoto coefficient as a distance metric in a K-Nearest Neighbors classifier for protein family classification. It demonstrates how Tanimoto similarity can be used to compare protein sequences and classify them into families.\n",
    "\n",
    "* **Drug-Target Interaction Prediction**:  This example demonstrates the use of Tanimoto coefficient in predicting drug-target interactions by generating synthetic data for drug fingerprints, target fingerprints, and their interactions, and then calculates the Tanimoto similarity between each drug-target pair. It combines the original fingerprints with the Tanimoto similarity as features for a machine learning model, trains a Random Forest classifier to predict drug-target interactions, evaluates the model using a ROC curve and visualizes the results and analyzes the importance of different features, including the Tanimoto similarity, in the prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee62e5-f53e-4fef-8e34-d8497b53fc66",
   "metadata": {},
   "source": [
    "Molecular Similarity in Drug Discovery:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff19be-0639-4fea-856e-8b7f2dded6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import DataStructs\n",
    "\n",
    "def tanimoto_similarity(fp1, fp2):\n",
    "    return DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "\n",
    "# Define SMILES strings for a reference drug and potential drug candidates\n",
    "reference_drug = \"CC(=O)OC1=CC=CC=C1C(=O)O\"  # Aspirin\n",
    "candidates = [\n",
    "    \"CC1=C(C(=O)NO)C(=O)C2=C(C=CC=C2)N1\",  # Piroxicam\n",
    "    \"CC1=CN=C(C(=O)NC2=C(C=CC(=C2)C(F)(F)F)N)C(=C1)OC3CCCC3\",  # Celecoxib\n",
    "    \"CC1=C(C=C(C=C1)NC(=O)C2=CC=C(C=C2)CN3CCN(CC3)C)NC4=NC=CC(=N4)C5=CN=CC=C5\",  # Imatinib\n",
    "    \"COC1=C(C=C2C(=C1)C(=O)C3=C(C2=O)C=CC=C3)O\",  # Doxorubicin\n",
    "]\n",
    "\n",
    "# Convert SMILES to RDKit molecules and generate Morgan fingerprints\n",
    "reference_mol = Chem.MolFromSmiles(reference_drug)\n",
    "reference_fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(reference_mol, 2, nBits=1024)\n",
    "\n",
    "candidate_mols = [Chem.MolFromSmiles(smiles) for smiles in candidates]\n",
    "candidate_fps = [rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024) for mol in candidate_mols]\n",
    "\n",
    "# Calculate Tanimoto similarities\n",
    "similarities = [tanimoto_similarity(reference_fp, fp) for fp in candidate_fps]\n",
    "\n",
    "# Visualize similarities\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(candidates)), similarities)\n",
    "plt.title(\"Molecular Similarity to Aspirin\")\n",
    "plt.xlabel(\"Candidate Drugs\")\n",
    "plt.ylabel(\"Tanimoto Similarity\")\n",
    "plt.xticks(range(len(candidates)), ['Piroxicam', 'Celecoxib', 'Imatinib', 'Doxorubicin'], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Tanimoto similarities to Aspirin:\")\n",
    "for i, sim in enumerate(similarities):\n",
    "    print(f\"{candidates[i]}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d6197-9b37-4ba0-befa-e93d8ec8e162",
   "metadata": {},
   "source": [
    "Protein Sequence Similarity Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340e6cc-9a45-4611-a145-39885c86d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools \n",
    "\n",
    "def sequence_to_kmer_binary(sequence, k=3, alphabet='ACDEFGHIKLMNPQRSTVWY'):\n",
    "    kmer_dict = {''.join(kmer): i for i, kmer in enumerate(itertools.product(alphabet, repeat=k))}\n",
    "    binary = np.zeros(len(kmer_dict))\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        kmer = sequence[i:i+k]\n",
    "        if kmer in kmer_dict:\n",
    "            binary[kmer_dict[kmer]] = 1\n",
    "    return binary\n",
    "\n",
    "def tanimoto_coefficient(A, B):\n",
    "    intersection = np.sum(A * B)\n",
    "    return intersection / (np.sum(A) + np.sum(B) - intersection)\n",
    "\n",
    "# Example protein sequences\n",
    "sequences = [\n",
    "    \"MKVLWAALLVTFLAGCQAKVEQAVETEPEPELRQQTEWQSGQRWELALGRFWDYLRWVQTLSEQVQEELLSSQVTQELRALMDETMKELKAYKSELEEQLTPVAEETRARLSKELQAAQARLGADMEDVCGRLVQYRGEVQAMLGQSTEELRVRLASHLRKLRKRLLRDADDLQKRLAVYQAGAREGAERGLSAIRERLGPLVEQGRVRAATVGSLAGQPLQERAQAWGERLRARMEEMGSRTRDRLDEVKEQVAEVRAKLEEQAQQRLGSSEDASKEYIENLKGLDKEFLKEGPGS\",\n",
    "    \"MKWVTFISLLLLFSSAYSRGVFRRDAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKSLHTLFGDKLCTVATLRETYGEMADCCAKQEPERNECFLQHKDDNPNLPRLVRPEVDVMCTAFHDNEETFLKKYLYEIARRHPYFYAPELLFFAKRYKAAFTECCQAADKAACLLPKLDELRDEGKASSAKQRLKCASLQKFGERAFKAWAVARLSQRFPKAEFAEVSKLVTDLTKVHTECCHGDLLECADDRADLAKYICENQDSISSKLKECCEKPLLEKSHCIAEVENDEMPADLPSLAADFVESKDVCKNYAEAKDVFLGMFLYEYARRHPDYSVVLLLRLAKTYETTLEKCCAAADPHECYAKVFDEFKPLVEEPQNLIKQNCELFEQLGEYKFQNALLVRYTKKVPQVSTPTLVEVSRNLGKVGSKCCKHPEAKRMPCAEDYLSVVLNQLCVLHEKTPVSDRVTKCCTESLVNRRPCFSALEVDETYVPKEFNAETFTFHADICTLSEKERQIKKQTALVELVKHKPKATKEQLKAVMDDFAAFVEKCCKADDKETCFAEEGKKLVAASQAALGL\",\n",
    "    \"MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAEDLQVGQVELGGGPGAGSLQPLALEGSLQKRGIVEQCCTSICSLYQLENYCN\",\n",
    "    \"MDSKNFGVLVFCLLLGVVSGSYGDLEKIAKTWKLKALYKQGLKSPIKELRLKQLFHITPETALETVQKLDLSPGQTVLLPQVDENKTFSEWLEAQKAKADALEFYQKKFPSWTKDQQLDDLSRKFSPKIKERLLSLGEVNLDDEVYAKFQDLGSIQKAYENKTSANDHLLNQFYQILGAVDITDKLSEIFLTTKLPKSLEKXSIEEKTNLEKFVEKALTTSVDKLTQVFNETIKIFEEDPAKNCHLNENIEKGLLHRFNPIKVSVEQMTSLKRSHEVTNCYYDDKSFKLNKKEGTSFLIRELQQVLQMLYVMDIFQRITKDLKTVIDSRKLLEALLKEGIETLQMKFHTIYDSNTELDFLRDHVHVSVSDIIKDNNYVPEEMFSSDFPTMTTMDLFVTVTETFNPLIYTYEQIPIAWDLGKKGPFDDSRAENETQDNLSYVLHVLNVTFNDTEGYITGNLPLQSITFGGFRFDLPFLEQKKYYPNSDKELKKIIGQVRDQLEETKQRLTTVAFHQIFALEEENQTLKQNLRDSPIRIAEIYSNKDNYKFTVEQTSATLHWMVPVILVPLIFILLLALGLSFYRLRKCVRFAEAKAERPRDNYQTIKRQAVSSIVASSCVSLLSLVITSIFITSMVMVVVAKFKTTVCPQAPEEPTCVPDYGYTVFPGFNSTQFSYVSNPTQAVILFLLSLIFMTHILVVISQKTSSYIELLKDVEVQDMKKTMKKLAVPMIITIILLFLFVTYFAVYMSLAADEEGNLENKVGNYQAKLQDHLDTEVERIRIAQALRDQNECQEREEKYNKFGPQHKLDLIQSLAKLKGMGHSEKPIGDVDMMYLRTFINQHQIPKDFSEFHNRVGNTFEKYPPVPRGIFQCIDKENTKAFFRNTDSIQLHHHHHH\",\n",
    "]\n",
    "\n",
    "# Convert sequences to binary vectors using k-mers\n",
    "binary_sequences = [sequence_to_kmer_binary(seq) for seq in sequences]\n",
    "\n",
    "# Calculate Tanimoto coefficients\n",
    "n = len(sequences)\n",
    "similarity_matrix = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        similarity_matrix[i, j] = tanimoto_coefficient(binary_sequences[i], binary_sequences[j])\n",
    "\n",
    "# Visualize similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix, annot=True, cmap='YlGnBu', fmt='.4f')\n",
    "plt.title(\"Protein Sequence Similarity Matrix (Tanimoto Coefficient)\")\n",
    "plt.xlabel(\"Protein Sequences\")\n",
    "plt.ylabel(\"Protein Sequences\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Tanimoto similarities between protein sequences:\")\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        print(f\"Sequence {i+1} vs Sequence {j+1}: {similarity_matrix[i, j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4d8c1-8e14-40c7-aff1-388d8e859ff3",
   "metadata": {},
   "source": [
    "Virtual Screening for Drug Discovery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8b6a6-31f9-4124-992f-74eec3851891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "def tanimoto_similarity(fp1, fp2):\n",
    "    return DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "\n",
    "# Define SMILES strings for a target protein binding site and a library of compounds\n",
    "target_site = \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\"  # Ibuprofen binding site\n",
    "compound_library = [\n",
    "    \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",  # Ibuprofen\n",
    "    \"CC1=C(C(=O)NO)C(=O)C2=C(C=CC=C2)N1\",  # Piroxicam\n",
    "    \"CC1=CN=C(C(=O)NC2=C(C=CC(=C2)C(F)(F)F)N)C(=C1)OC3CCCC3\",  # Celecoxib\n",
    "    \"CC1=C(C=C(C=C1)NC(=O)C2=CC=C(C=C2)CN3CCN(CC3)C)NC4=NC=CC(=N4)C5=CN=CC=C5\",  # Imatinib\n",
    "    \"COC1=C(C=C2C(=C1)C(=O)C3=C(C2=O)C=CC=C3)O\",  # Doxorubicin\n",
    "]\n",
    "\n",
    "# Convert SMILES to RDKit molecules and generate Morgan fingerprints\n",
    "target_mol = Chem.MolFromSmiles(target_site)\n",
    "target_fp = AllChem.GetMorganFingerprintAsBitVect(target_mol, 2, nBits=1024)\n",
    "\n",
    "compound_mols = [Chem.MolFromSmiles(smiles) for smiles in compound_library]\n",
    "compound_fps = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024) for mol in compound_mols]\n",
    "\n",
    "# Calculate Tanimoto similarities\n",
    "similarities = [tanimoto_similarity(target_fp, fp) for fp in compound_fps]\n",
    "\n",
    "# Visualize similarities\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(compound_library)), similarities)\n",
    "plt.title(\"Virtual Screening Results\")\n",
    "plt.xlabel(\"Compounds\")\n",
    "plt.ylabel(\"Tanimoto Similarity to Target\")\n",
    "plt.xticks(range(len(compound_library)), ['Ibuprofen', 'Piroxicam', 'Celecoxib', 'Imatinib', 'Doxorubicin'], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sort compounds by similarity\n",
    "sorted_compounds = sorted(zip(compound_library, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Virtual screening results:\")\n",
    "for compound, similarity in sorted_compounds:\n",
    "    print(f\"Compound: {compound}\")\n",
    "    print(f\"Similarity to target: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40da02c4-e526-4a05-a354-a76d4758adc0",
   "metadata": {},
   "source": [
    "Protein Family Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74fc5b-d04c-4aad-b6aa-11e7c889311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def sequence_to_binary(sequence, alphabet='ACDEFGHIKLMNPQRSTVWY'):\n",
    "    binary = np.zeros(len(alphabet), dtype=int)\n",
    "    for aa in sequence:\n",
    "        if aa in alphabet:\n",
    "            binary[alphabet.index(aa)] = 1\n",
    "    return binary\n",
    "\n",
    "def tanimoto_coefficient(A, B):\n",
    "    intersection = np.sum(A * B)\n",
    "    return intersection / (np.sum(A) + np.sum(B) - intersection)\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "sequence_length = 100\n",
    "\n",
    "sequences = [''.join(np.random.choice(list('ACDEFGHIKLMNPQRSTVWY'), size=sequence_length)) for _ in range(n_samples)]\n",
    "families = np.random.randint(3, size=n_samples)  # 3 protein families\n",
    "\n",
    "# Convert sequences to binary vectors\n",
    "X = np.array([sequence_to_binary(seq) for seq in sequences])\n",
    "y = families\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a KNN model using Tanimoto coefficient as metric\n",
    "model = KNeighborsClassifier(n_neighbors=5, metric=tanimoto_coefficient)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Protein Family Classification')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb2892-c86d-41f2-a3c8-919d9a07153f",
   "metadata": {},
   "source": [
    "Drug-Target Interaction Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1343bd0-6ce6-4b6c-8567-b06197239de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Tanimoto similarities\n",
    "similarities = np.array([tanimoto_coefficient(drug, target) for drug, target in zip(drug_fingerprints, target_fingerprints)])\n",
    "\n",
    "# Combine similarities with original fingerprints\n",
    "X = np.hstack((drug_fingerprints, target_fingerprints, similarities.reshape(-1, 1)))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities and calculate ROC curve\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Drug-Target Interaction Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "tanimoto_importance = feature_importance[-1]\n",
    "\n",
    "print(f\"Importance of Tanimoto similarity in the model: {tanimoto_importance:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Drug Fingerprints', 'Target Fingerprints', 'Tanimoto Similarity'], \n",
    "        [np.mean(feature_importance[:1024]), np.mean(feature_importance[1024:-1]), tanimoto_importance])\n",
    "plt.title('Feature Importance in Drug-Target Interaction Prediction')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d7814-6ed1-4633-9aab-949161979e0d",
   "metadata": {},
   "source": [
    "## Instances where we use the Cosine Similarity Equation: cos(θ) = (A · B) / (||A|| ||B||)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea882a-1fe1-4aaf-a22d-34fb79608424",
   "metadata": {},
   "source": [
    "These examples showcase how cosine similarity can be applied in various aspects of protein research and drug discovery. Cosine similarity is particularly useful in these fields because it captures the similarity in direction (rather than magnitude) between vectors, making it effective for comparing high-dimensional data like protein sequences, molecular fingerprints, or feature vectors.\n",
    "\n",
    "* **Protein Sequence Comparison:**  This snippet compares protein sequences using cosine similarity. It converts protein sequences to n-gram representations, then calculates and visualizes the similarities. This is useful for identifying related proteins or protein families.\n",
    "\n",
    "* **Drug-Target Interaction Prediction:**  This example uses cosine similarity as a feature in predicting drug-target interactions. It demonstrates how cosine similarity can capture the relationship between drug and target features, potentially improving prediction accuracy.\n",
    "\n",
    "* **Protein Structure Comparison**:  This snippet compares protein structures using cosine similarity. While simplified (real protein structure comparison would involve more complex representations), it demonstrates how cosine similarity can be used to compare 3D structures, which is crucial in structural biology and drug design.\n",
    "\n",
    "* **Virtual Screening for Drug Discovery**:  This example performs virtual screening by comparing molecular fingerprints using cosine similarity. It's useful in drug discovery for identifying compounds similar to a known active compound or drug target.\n",
    "\n",
    "* **Protein Function Prediction**:  This example uses cosine similarity in a K-Nearest Neighbors classifier to predict protein functions based on their sequences. It demonstrates how cosine similarity can be used in machine learning models for protein analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c5c54-4de9-429a-a787-8693dd6f10a4",
   "metadata": {},
   "source": [
    "Protein Sequence Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16230831-c919-4aa5-9a88-cda7de63dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def protein_to_ngrams(sequence, n=3):\n",
    "    return ' '.join([sequence[i:i+n] for i in range(len(sequence)-n+1)])\n",
    "\n",
    "# Example protein sequences\n",
    "proteins = [\n",
    "    \"MKVLWAALLVTFLAGCQAKVEQAVETEPEPELRQQTEWQSGQRWELALGRFWDYLRWVQTLSEQVQEELLSSQVTQELRALMDETMKE\",\n",
    "    \"MKWVTFISLLLLFSSAYSRGVFRRDAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCD\",\n",
    "    \"MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAEDLQVGQVELGGGPGAGSLQPLALEGSLQ\",\n",
    "    \"MDSKNFGVLVFCLLLGVVSGSYGDLEKIAKTWKLKALYKQGLKSPIKELRLKQLFHITPETALETVQKLDLSPGQTVLLPQVDENKT\",\n",
    "]\n",
    "\n",
    "# Convert proteins to n-gram representation\n",
    "protein_ngrams = [protein_to_ngrams(p) for p in proteins]\n",
    "\n",
    "# Create vector representations\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(protein_ngrams)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = cosine_similarity(X)\n",
    "\n",
    "# Visualize similarities\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(similarities, cmap='YlOrRd')\n",
    "plt.colorbar()\n",
    "plt.title(\"Protein Sequence Similarities (Cosine)\")\n",
    "plt.xlabel(\"Protein Index\")\n",
    "plt.ylabel(\"Protein Index\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print similarities\n",
    "for i in range(len(proteins)):\n",
    "    for j in range(i+1, len(proteins)):\n",
    "        print(f\"Similarity between protein {i+1} and {j+1}: {similarities[i,j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b40b7-8c9a-4317-bcfe-0006a3200fcd",
   "metadata": {},
   "source": [
    "Drug-Target Interaction Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9002654-479a-4f30-854a-d94a7ffd1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    return np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 100\n",
    "\n",
    "drugs = np.random.rand(n_samples, n_features)\n",
    "targets = np.random.rand(n_samples, n_features)\n",
    "interactions = np.random.randint(2, size=n_samples)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = np.array([cosine_similarity(d, t) for d, t in zip(drugs, targets)])\n",
    "\n",
    "# Prepare data for classification\n",
    "X = np.column_stack((drugs, targets, similarities.reshape(-1, 1)))\n",
    "y = interactions\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Simple logistic regression (you could use a more complex model)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities and calculate ROC curve\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Drug-Target Interaction Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance\n",
    "feature_importance = abs(model.coef_[0])\n",
    "print(f\"Importance of cosine similarity: {feature_importance[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b8a5a-773f-4820-9989-a02fd6f691f1",
   "metadata": {},
   "source": [
    "Protein Structure Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a901e-f250-4b5d-ad96-370ad2b21414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def generate_random_structure(n_residues):\n",
    "    return np.random.rand(n_residues, 3)\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    return np.dot(A.flatten(), B.flatten()) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "\n",
    "# Generate random protein structures\n",
    "n_structures = 5\n",
    "n_residues = 50\n",
    "structures = [generate_random_structure(n_residues) for _ in range(n_structures)]\n",
    "\n",
    "# Calculate pairwise cosine similarities\n",
    "similarities = np.zeros((n_structures, n_structures))\n",
    "for i in range(n_structures):\n",
    "    for j in range(n_structures):\n",
    "        similarities[i, j] = cosine_similarity(structures[i], structures[j])\n",
    "\n",
    "# Visualize similarities\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(similarities, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title(\"Protein Structure Similarities (Cosine)\")\n",
    "plt.xlabel(\"Structure Index\")\n",
    "plt.ylabel(\"Structure Index\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the first structure\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(structures[0][:, 0], structures[0][:, 1], structures[0][:, 2])\n",
    "ax.set_title(\"Example Protein Structure\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.show()\n",
    "\n",
    "# Print similarities\n",
    "for i in range(n_structures):\n",
    "    for j in range(i+1, n_structures):\n",
    "        print(f\"Similarity between structure {i+1} and {j+1}: {similarities[i,j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50220d68-73f2-450c-931f-6e74c72b2ab9",
   "metadata": {},
   "source": [
    "Virtual Screening for Drug Discovery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f39eb-41c3-4ef6-a5e8-e66c44482f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def morgan_fingerprint(smiles, radius=2, nBits=2048):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    return np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "\n",
    "# Example SMILES strings\n",
    "target = \"CC(=O)OC1=CC=CC=C1C(=O)O\"  # Aspirin\n",
    "compounds = [\n",
    "    \"CC(=O)OC1=CC=CC=C1C(=O)O\",  # Aspirin\n",
    "    \"CC1=C(C(=O)NO)C(=O)C2=C(C=CC=C2)N1\",  # Piroxicam\n",
    "    \"CC1=CN=C(C(=O)NC2=C(C=CC(=C2)C(F)(F)F)N)C(=C1)OC3CCCC3\",  # Celecoxib\n",
    "    \"COC1=C(C=C2C(=C1)C(=O)C3=C(C2=O)C=CC=C3)O\",  # Doxorubicin\n",
    "]\n",
    "\n",
    "# Generate fingerprints\n",
    "target_fp = morgan_fingerprint(target)\n",
    "compound_fps = [morgan_fingerprint(c) for c in compounds]\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = [cosine_similarity(target_fp, fp) for fp in compound_fps]\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(compounds)), similarities)\n",
    "plt.title(\"Compound Similarities to Aspirin\")\n",
    "plt.xlabel(\"Compounds\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.xticks(range(len(compounds)), ['Aspirin', 'Piroxicam', 'Celecoxib', 'Doxorubicin'], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print similarities\n",
    "for i, sim in enumerate(similarities):\n",
    "    print(f\"Similarity of {compounds[i]} to Aspirin: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4638a6-8181-4112-819d-78202a8a955b",
   "metadata": {},
   "source": [
    "Protein Function Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c23996-7c61-4ab3-8861-78c8d4bc9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def protein_to_ngrams(sequence, n=3):\n",
    "    return ' '.join([sequence[i:i+n] for i in range(len(sequence)-n+1)])\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "sequence_length = 100\n",
    "n_classes = 3\n",
    "\n",
    "sequences = [''.join(np.random.choice(list('ACDEFGHIKLMNPQRSTVWY'), size=sequence_length)) for _ in range(n_samples)]\n",
    "functions = np.random.randint(n_classes, size=n_samples)\n",
    "\n",
    "# Convert sequences to n-gram representation\n",
    "sequence_ngrams = [protein_to_ngrams(s) for s in sequences]\n",
    "\n",
    "# Create vector representations\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sequence_ngrams)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, functions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a KNN classifier using cosine similarity\n",
    "clf = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize example similarities\n",
    "example_similarities = cosine_similarity(X_test[:5], X_test[:5])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(example_similarities, cmap='YlOrRd')\n",
    "plt.colorbar()\n",
    "plt.title(\"Example Protein Similarities (Cosine)\")\n",
    "plt.xlabel(\"Protein Index\")\n",
    "plt.ylabel(\"Protein Index\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3cdbf-dd1b-40f3-b5c5-1107bf480742",
   "metadata": {},
   "source": [
    "## Instances where we use the Z-score Normalization Equation: z = (x - μ) / σ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e66502-613f-4a17-a329-efc215969d90",
   "metadata": {},
   "source": [
    "These examples showcase how we use the Z-score Normalization Equation: z = (x - μ) / σ and how it can be applied in various aspects of protein research and drug discovery. These examples demonstrate the importance of Z-score normalization in various aspects of protein quality scoring and drug discovery. They standardize the data, making it easier to compare different measurements or features, they help identify outliers or unusual data points, improve the performance of machine learning models by putting all features on the same scale, they allow for fair comparison between different experiments or datasets and finally they can reveal patterns or relationships that might be obscured in the raw data.\n",
    "\n",
    "* **Protein Structure Quality Assessment:**  This snippet simulates protein structure quality scores and applies Z-score normalization. It helps identify potentially problematic structures by setting a threshold on the Z-scores. The visualization shows how Z-score normalization standardizes the distribution, making it easier to spot outliers.\n",
    "\n",
    "* **Drug Solubility Comparison:**  This example simulates solubility data for different drug compounds and applies Z-score normalization. It allows for a fair comparison between compounds with different scales of solubility. The visualization shows how Z-score normalization puts all compounds on the same scale.\n",
    "\n",
    "* **Gene Expression Analysis for Drug Response**:  This snippet simulates gene expression data and drug response, then uses Z-score normalization to standardize gene expression across samples. It demonstrates how normalization can help in identifying genes correlated with drug response. The visualization shows the effect of normalization on the expression data.\n",
    "\n",
    "* **Protein-Ligand Binding Affinity Prediction**:  This example simulates protein-ligand features and binding affinities, then compares the performance of a linear regression model with and without Z-score normalization. It demonstrates how normalization can improve the model's performance in predicting binding affinities.\n",
    "\n",
    "* **Drug Candidate Screening**:  This example simulates drug properties and applies a simplified version of Lipinski's Rule of Five for drug-likeness screening. It compares the screening results with and without Z-score normalization. The visualization shows how normalization affects the distribution of each property and the final screening scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bd86c-2967-434d-bab3-20422944dcb1",
   "metadata": {},
   "source": [
    "Protein Structure Quality Assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d28d79d-ac50-4895-a3ad-03527e9b90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated protein structure quality scores\n",
    "np.random.seed(42)\n",
    "n_structures = 1000\n",
    "quality_scores = np.random.normal(loc=50, scale=10, size=n_structures)\n",
    "\n",
    "# Add some outliers\n",
    "quality_scores[:10] += 50\n",
    "\n",
    "# Z-score normalization\n",
    "z_scores = stats.zscore(quality_scores)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(quality_scores, bins=30, edgecolor='black')\n",
    "plt.title('Original Quality Scores')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(z_scores, bins=30, edgecolor='black')\n",
    "plt.title('Z-score Normalized Quality Scores')\n",
    "plt.xlabel('Z-score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify potential problematic structures\n",
    "threshold = 3\n",
    "problematic = np.abs(z_scores) > threshold\n",
    "print(f\"Number of potentially problematic structures: {np.sum(problematic)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc6dbf-7fec-4904-9f35-b9705874e7ab",
   "metadata": {},
   "source": [
    "Drug Solubility Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf957069-91ef-42d3-bc08-7c46b9ab6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated solubility data for different drug compounds\n",
    "np.random.seed(42)\n",
    "n_compounds = 50\n",
    "solubility_data = {\n",
    "    'Compound A': np.random.normal(loc=-2, scale=0.5, size=n_compounds),\n",
    "    'Compound B': np.random.normal(loc=0, scale=1, size=n_compounds),\n",
    "    'Compound C': np.random.normal(loc=2, scale=1.5, size=n_compounds)\n",
    "}\n",
    "\n",
    "# Z-score normalization\n",
    "normalized_data = {k: stats.zscore(v) for k, v in solubility_data.items()}\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Original data\n",
    "pd.DataFrame(solubility_data).boxplot(ax=ax1)\n",
    "ax1.set_title('Original Solubility Data')\n",
    "ax1.set_ylabel('Log Solubility')\n",
    "\n",
    "# Normalized data\n",
    "pd.DataFrame(normalized_data).boxplot(ax=ax2)\n",
    "ax2.set_title('Z-score Normalized Solubility Data')\n",
    "ax2.set_ylabel('Z-score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare compounds\n",
    "for compound in normalized_data:\n",
    "    mean_z = np.mean(normalized_data[compound])\n",
    "    print(f\"{compound} mean Z-score: {mean_z:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f2c51-b0a8-4390-a4ca-01fc59194c58",
   "metadata": {},
   "source": [
    "Gene Expression Analysis for Drug Response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea1f4d-2610-4763-a523-ccfebb85e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated gene expression data\n",
    "np.random.seed(42)\n",
    "n_genes = 1000\n",
    "n_samples = 50\n",
    "expression_data = np.random.normal(loc=5, scale=2, size=(n_genes, n_samples))\n",
    "\n",
    "# Simulated drug response\n",
    "drug_response = np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "\n",
    "# Z-score normalization of gene expression\n",
    "normalized_expression = stats.zscore(expression_data, axis=1)\n",
    "\n",
    "# Correlation analysis\n",
    "correlations = np.array([np.corrcoef(normalized_expression[i], drug_response)[0, 1] for i in range(n_genes)])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "sns.heatmap(expression_data[:10], cmap='viridis')\n",
    "plt.title('Original Expression Data (First 10 Genes)')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Genes')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.heatmap(normalized_expression[:10], cmap='viridis')\n",
    "plt.title('Z-score Normalized Expression Data (First 10 Genes)')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Genes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot correlation distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(correlations, bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Gene-Drug Response Correlations')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Identify top correlated genes\n",
    "top_genes = np.argsort(np.abs(correlations))[-10:]\n",
    "print(\"Top correlated genes (indices):\", top_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0cab92-53a4-4ac0-884b-ed8419054336",
   "metadata": {},
   "source": [
    "Protein-Ligand Binding Affinity Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e91dab0-2c95-4ba8-a421-20c80c7dded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Simulated protein-ligand features and binding affinities\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "X = np.random.rand(n_samples, n_features)\n",
    "y = 2 * X[:, 0] + 0.5 * X[:, 1] - X[:, 2] + 0.1 * X[:, 3] - 0.5 * X[:, 4] + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "model_raw = LinearRegression().fit(X_train, y_train)\n",
    "model_normalized = LinearRegression().fit(X_train_normalized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "y_pred_normalized = model_normalized.predict(X_test_normalized)\n",
    "\n",
    "# Evaluation\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw)\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "mse_normalized = mean_squared_error(y_test, y_pred_normalized)\n",
    "r2_normalized = r2_score(y_test, y_pred_normalized)\n",
    "\n",
    "print(f\"Raw data - MSE: {mse_raw:.4f}, R2: {r2_raw:.4f}\")\n",
    "print(f\"Normalized data - MSE: {mse_normalized:.4f}, R2: {r2_normalized:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.scatter(y_test, y_pred_raw, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.title('Predictions with Raw Data')\n",
    "plt.xlabel('Actual Binding Affinity')\n",
    "plt.ylabel('Predicted Binding Affinity')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(y_test, y_pred_normalized, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.title('Predictions with Normalized Data')\n",
    "plt.xlabel('Actual Binding Affinity')\n",
    "plt.ylabel('Predicted Binding Affinity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810ccd8-f270-4414-86a2-7a9337572d6a",
   "metadata": {},
   "source": [
    "Drug Candidate Screening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53672c35-590d-4cae-9074-d4c6cedc64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated drug properties\n",
    "np.random.seed(42)\n",
    "n_candidates = 1000\n",
    "molecular_weight = np.random.normal(loc=300, scale=50, size=n_candidates)\n",
    "logP = np.random.normal(loc=2, scale=1, size=n_candidates)\n",
    "h_bond_donors = np.random.poisson(lam=2, size=n_candidates)\n",
    "h_bond_acceptors = np.random.poisson(lam=5, size=n_candidates)\n",
    "\n",
    "# Combine properties\n",
    "properties = np.column_stack([molecular_weight, logP, h_bond_donors, h_bond_acceptors])\n",
    "\n",
    "# Z-score normalization\n",
    "normalized_properties = stats.zscore(properties, axis=0)\n",
    "\n",
    "# Lipinski's Rule of Five score (simplified)\n",
    "def lipinski_score(mw, logp, hbd, hba):\n",
    "    return (mw <= 500) + (logp <= 5) + (hbd <= 5) + (hba <= 10)\n",
    "\n",
    "raw_scores = np.apply_along_axis(lambda x: lipinski_score(*x), 1, properties)\n",
    "normalized_scores = np.apply_along_axis(lambda x: lipinski_score(*x), 1, normalized_properties)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "for i, (prop, name) in enumerate(zip(properties.T, ['Molecular Weight', 'LogP', 'H-Bond Donors', 'H-Bond Acceptors'])):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.hist(prop, bins=30, alpha=0.5, label='Original')\n",
    "    ax.hist(normalized_properties[:, i], bins=30, alpha=0.5, label='Normalized')\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(raw_scores, bins=5, alpha=0.5, label='Original')\n",
    "plt.hist(normalized_scores, bins=5, alpha=0.5, label='Normalized')\n",
    "plt.title(\"Distribution of Lipinski's Rule of Five Scores\")\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Candidates passing all rules (original): {np.sum(raw_scores == 4)}\")\n",
    "print(f\"Candidates passing all rules (normalized): {np.sum(normalized_scores == 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e9382-565e-42f1-b35b-6b439174b883",
   "metadata": {},
   "source": [
    "## Instances where we use the Euclidean Distance Equation: d(p,q) = √(Σ(i=1 to n) (p_i - q_i)^2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c773c-60d6-4f87-aaf9-580d0218086b",
   "metadata": {},
   "source": [
    "The following examples demonstrate the importance of the Euclidean distance in various aspects of protein quality scoring and drug discovery.  They help to quantify structural similarities between proteins or binding sites, measure the fit between drugs and pharmacophore models, help cluster similar conformations or poses in molecular docking, they underlie many machine learning algorithms used in QSAR and other predictive models and provide a basis for comparing multi-dimensional data in chemical space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1bf2c-70e7-4f01-b233-28bbc5d7313d",
   "metadata": {},
   "source": [
    "* **Protein Structure Comparison:**  This snippet generates two random protein structures and calculates the Euclidean distance between them. It visualizes the structures in 3D space and shows the residue-wise distances. This is useful for comparing protein conformations or assessing structural similarities.\n",
    "\n",
    "* **Drug-Target Binding Site Similarity:**  This example simulates binding site features and calculates pairwise Euclidean distances. It visualizes the distance matrix and a 2D projection of the binding sites. This approach is useful for identifying similar binding sites or potential cross-reactivity between drugs.\n",
    "\n",
    "* **Pharmacophore Modeling:**:  This snippet simulates a reference pharmacophore and candidate molecules, then calculates their distances. It visualizes the 3D pharmacophore models, overall distances, and feature-wise distances. This approach is useful in drug design for identifying molecules that match a desired pharmacophore.\n",
    "\n",
    "* **Protein-Ligand Docking Pose Clustering:**:  This example simulates protein-ligand docking poses and uses the Euclidean distance-based RMSD to cluster them. It visualizes the distance matrix and a dendrogram of the hierarchical clustering. This approach is useful for identifying representative poses from docking simulations.\n",
    "\n",
    "* **Quantitative Structure-Activity Relationship (QSAR) Analysis:**:  This snippet simulates a QSAR dataset and uses a k-Nearest Neighbors model (which relies on Euclidean distance) to predict activities. It visualizes the model's predictions and descriptor importances. This approach is useful for predicting biological activities of new compounds based on their molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420e07f-8e7c-4620-bfd6-b5e31c77b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "Protein Structure Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb129d-9b47-4277-a7c8-6dea08bb60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def generate_protein_structure(n_residues):\n",
    "    return np.random.rand(n_residues, 3)\n",
    "\n",
    "# Generate two protein structures\n",
    "n_residues = 50\n",
    "protein_A = generate_protein_structure(n_residues)\n",
    "protein_B = generate_protein_structure(n_residues)\n",
    "\n",
    "# Calculate Euclidean distance between structures\n",
    "distance = euclidean(protein_A.flatten(), protein_B.flatten())\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(protein_A[:, 0], protein_A[:, 1], protein_A[:, 2], c='r', label='Protein A')\n",
    "ax1.scatter(protein_B[:, 0], protein_B[:, 1], protein_B[:, 2], c='b', label='Protein B')\n",
    "ax1.set_title('Protein Structures')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(range(n_residues), np.linalg.norm(protein_A - protein_B, axis=1))\n",
    "ax2.set_title('Residue-wise Euclidean Distance')\n",
    "ax2.set_xlabel('Residue Index')\n",
    "ax2.set_ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Overall Euclidean distance between structures: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c205650-9df5-471b-84f6-f73ae4271394",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drug-Target Binding Site Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253c07c-32d1-43ce-8df3-bf1cd2277bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Generate synthetic binding site features\n",
    "n_sites = 100\n",
    "n_features = 10\n",
    "binding_sites = np.random.rand(n_sites, n_features)\n",
    "\n",
    "# Calculate pairwise Euclidean distances\n",
    "distances = np.zeros((n_sites, n_sites))\n",
    "for i in range(n_sites):\n",
    "    for j in range(n_sites):\n",
    "        distances[i, j] = euclidean(binding_sites[i], binding_sites[j])\n",
    "\n",
    "# Perform PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "binding_sites_2d = pca.fit_transform(binding_sites)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(distances, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Pairwise Euclidean Distances')\n",
    "plt.xlabel('Binding Site Index')\n",
    "plt.ylabel('Binding Site Index')\n",
    "\n",
    "plt.subplot(122)\n",
    "scatter = plt.scatter(binding_sites_2d[:, 0], binding_sites_2d[:, 1], c=distances[0], cmap='viridis')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('Binding Sites in 2D (PCA)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Range of distances: {np.min(distances):.4f} to {np.max(distances):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb53cdd-5a19-435c-943c-64b470bede83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pharmacophore Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a377ed0-24e9-43bb-bf36-269add5a05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Generate a reference pharmacophore\n",
    "ref_pharmacophore = np.array([\n",
    "    [0, 0, 0],  # Hydrophobic center\n",
    "    [3, 0, 0],  # Hydrogen bond donor\n",
    "    [0, 3, 0],  # Hydrogen bond acceptor\n",
    "    [0, 0, 3]   # Aromatic ring center\n",
    "])\n",
    "\n",
    "# Generate some candidate molecules\n",
    "n_candidates = 5\n",
    "candidates = [ref_pharmacophore + np.random.normal(0, 0.5, (4, 3)) for _ in range(n_candidates)]\n",
    "\n",
    "# Calculate distances to reference pharmacophore\n",
    "distances = [euclidean(ref_pharmacophore.flatten(), c.flatten()) for c in candidates]\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(*ref_pharmacophore.T, c='r', s=100, label='Reference')\n",
    "for i, c in enumerate(candidates):\n",
    "    ax1.scatter(*c.T, alpha=0.7, label=f'Candidate {i+1}')\n",
    "ax1.set_title('Pharmacophore Models')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.bar(range(n_candidates), distances)\n",
    "ax2.set_title('Distances to Reference Pharmacophore')\n",
    "ax2.set_xlabel('Candidate Index')\n",
    "ax2.set_ylabel('Euclidean Distance')\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "for i, c in enumerate(candidates):\n",
    "    distances_to_ref = [euclidean(ref_pharmacophore[j], c[j]) for j in range(4)]\n",
    "    ax3.plot(range(4), distances_to_ref, marker='o', label=f'Candidate {i+1}')\n",
    "ax3.set_title('Feature-wise Distances')\n",
    "ax3.set_xlabel('Feature Index')\n",
    "ax3.set_ylabel('Euclidean Distance')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Distances to reference pharmacophore:\")\n",
    "for i, d in enumerate(distances):\n",
    "    print(f\"Candidate {i+1}: {d:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eceb9b-d1e0-456c-99a6-7d7eddca3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Protein-Ligand Docking Pose Clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da279b1-2d9f-4c2a-94ad-22efbf98834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Generate synthetic docking poses\n",
    "n_poses = 50\n",
    "n_atoms = 10\n",
    "poses = np.random.rand(n_poses, n_atoms, 3)\n",
    "\n",
    "# Calculate pairwise RMSD (root-mean-square deviation, based on Euclidean distance)\n",
    "def rmsd(pose1, pose2):\n",
    "    return np.sqrt(np.mean(np.sum((pose1 - pose2)**2, axis=1)))\n",
    "\n",
    "distance_matrix = np.zeros((n_poses, n_poses))\n",
    "for i in range(n_poses):\n",
    "    for j in range(i+1, n_poses):\n",
    "        distance_matrix[i, j] = distance_matrix[j, i] = rmsd(poses[i], poses[j])\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "linkage_matrix = linkage(squareform(distance_matrix), method='ward')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(distance_matrix, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Pairwise RMSD Matrix')\n",
    "plt.xlabel('Pose Index')\n",
    "plt.ylabel('Pose Index')\n",
    "\n",
    "plt.subplot(122)\n",
    "dendrogram(linkage_matrix)\n",
    "plt.title('Hierarchical Clustering of Docking Poses')\n",
    "plt.xlabel('Pose Index')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Range of RMSD values: {np.min(distance_matrix):.4f} to {np.max(distance_matrix):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cc617-aafc-4dae-a26b-4e43318a4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantitative Structure-Activity Relationship (QSAR) Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d147d-78a1-4bd9-aec5-bb5e666e190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate synthetic molecular descriptors and activities\n",
    "n_compounds = 100\n",
    "n_descriptors = 5\n",
    "X = np.random.rand(n_compounds, n_descriptors)\n",
    "y = 3*X[:, 0] - 2*X[:, 1] + X[:, 2] + 0.5*X[:, 3] - X[:, 4] + np.random.normal(0, 0.1, n_compounds)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a k-NN model (which uses Euclidean distance)\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Predicted vs Actual Activity')\n",
    "plt.xlabel('Actual Activity')\n",
    "plt.ylabel('Predicted Activity')\n",
    "\n",
    "plt.subplot(122)\n",
    "importances = np.abs(np.corrcoef(X_train.T, y_train)[:-1, -1])\n",
    "plt.bar(range(n_descriptors), importances)\n",
    "plt.title('Descriptor Importances')\n",
    "plt.xlabel('Descriptor Index')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60fa94-c5d5-4a23-b6c0-edff3945431d",
   "metadata": {},
   "source": [
    "## Instances where we use the Pearson Correlation Coefficient Equation: r = cov(X,Y) / (σ_X · σ_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd644a6-32c2-48b3-a348-2f9e0a55c795",
   "metadata": {},
   "source": [
    "The following examples demonstrate the importance of the Pearson Correlation Coefficient in various aspects of protein quality scoring and drug discovery.  They help quantify relationships between gene expression and drug response, assess correlations between different protein structure quality metrics, help to identify important molecular descriptors in QSAR studies, measure similarities between protein sequences based on their composition and finally evaluate potential synergies in drug combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f8641-852a-476a-829f-b5959dd14fad",
   "metadata": {},
   "source": [
    "* **Gene Expression Analysis for Drug Response:**  This example simulates gene expression data and drug response, then calculates the Pearson correlation between each gene and the drug response. It visualizes the relationship for one gene and the distribution of correlations for all genes. This approach is useful for identifying genes that might be involved in drug response mechanisms.\n",
    "\n",
    "* **Protein Structure Quality Assessment:**  This snippet simulates protein structure quality metrics and calculates correlations between them. It visualizes the relationships between resolution, R-free, and clashscore. This approach is useful for understanding how different quality metrics relate to each other and for assessing the overall quality of protein structures.\n",
    "* **Quantitative Structure-Activity Relationship (QSAR) Analysis**:  This example simulates molecular descriptors and activity data for a set of compounds, then calculates correlations between descriptors and activity. It visualizes the correlation matrix of descriptors and the correlations with activity. This approach is useful in QSAR studies for identifying which molecular properties are most strongly related to biological activity.\n",
    "\n",
    "* **Protein Sequence Similarity Analysis**:  This snippet generates synthetic protein sequences and uses Pearson correlation to measure their similarities based on base composition. It visualizes the similarity matrix and the distribution of pairwise correlations. This approach can be useful for clustering similar proteins or identifying potential homologs.\n",
    "\n",
    "* **Drug Combination Synergy Analysis**:  This example simulates dose-response data for two drugs and their combination, then uses Pearson correlation to assess the relationship between individual drug responses and the combination response. It visualizes the dose-response curves and the correlations between individual and combination responses. This approach can be useful for identifying potential synergistic drug combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76902402-ba89-4607-8b79-6351167bb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene Expression Analysis for Drug Response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d52c7c-b84c-4a36-a600-eb4c4c68b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Generate synthetic gene expression data and drug response\n",
    "np.random.seed(42)\n",
    "n_genes = 1000\n",
    "n_samples = 50\n",
    "\n",
    "gene_expression = np.random.normal(loc=0, scale=1, size=(n_genes, n_samples))\n",
    "drug_response = 2 * gene_expression[0] + np.random.normal(loc=0, scale=0.5, size=n_samples)\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "correlations = np.array([stats.pearsonr(gene_expression[i], drug_response)[0] for i in range(n_genes)])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(gene_expression[0], drug_response)\n",
    "plt.title(f'Gene 0 vs Drug Response\\nCorrelation: {correlations[0]:.2f}')\n",
    "plt.xlabel('Gene Expression')\n",
    "plt.ylabel('Drug Response')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(correlations, bins=50)\n",
    "plt.title('Distribution of Gene-Drug Response Correlations')\n",
    "plt.xlabel('Pearson Correlation Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify top correlated genes\n",
    "top_genes = np.argsort(np.abs(correlations))[-5:]\n",
    "print(\"Top correlated genes (indices):\", top_genes)\n",
    "print(\"Their correlations:\", correlations[top_genes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f98ce-078d-4a92-9d57-17e5ac104bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Protein Structure Quality Assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03420440-f912-4f8a-adf3-3ce07eebb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Generate synthetic quality metrics for protein structures\n",
    "n_structures = 100\n",
    "resolution = np.random.uniform(1.5, 3.5, n_structures)\n",
    "r_free = 0.2 * resolution + np.random.normal(0, 0.02, n_structures)\n",
    "clashscore = 10 * resolution + np.random.normal(0, 5, n_structures)\n",
    "\n",
    "# Calculate Pearson correlations\n",
    "corr_resolution_rfree = stats.pearsonr(resolution, r_free)[0]\n",
    "corr_resolution_clashscore = stats.pearsonr(resolution, clashscore)[0]\n",
    "corr_rfree_clashscore = stats.pearsonr(r_free, clashscore)[0]\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].scatter(resolution, r_free)\n",
    "axes[0].set_title(f'Resolution vs R-free\\nCorrelation: {corr_resolution_rfree:.2f}')\n",
    "axes[0].set_xlabel('Resolution (Å)')\n",
    "axes[0].set_ylabel('R-free')\n",
    "\n",
    "axes[1].scatter(resolution, clashscore)\n",
    "axes[1].set_title(f'Resolution vs Clashscore\\nCorrelation: {corr_resolution_clashscore:.2f}')\n",
    "axes[1].set_xlabel('Resolution (Å)')\n",
    "axes[1].set_ylabel('Clashscore')\n",
    "\n",
    "axes[2].scatter(r_free, clashscore)\n",
    "axes[2].set_title(f'R-free vs Clashscore\\nCorrelation: {corr_rfree_clashscore:.2f}')\n",
    "axes[2].set_xlabel('R-free')\n",
    "axes[2].set_ylabel('Clashscore')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Correlation between Resolution and R-free: {corr_resolution_rfree:.2f}\")\n",
    "print(f\"Correlation between Resolution and Clashscore: {corr_resolution_clashscore:.2f}\")\n",
    "print(f\"Correlation between R-free and Clashscore: {corr_rfree_clashscore:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db4073-8145-410a-9b94-eefadcde50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantitative Structure-Activity Relationship (QSAR) Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ea6e9-ec05-4c1d-8fde-b600d577a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Generate synthetic molecular descriptors and activity data\n",
    "n_compounds = 100\n",
    "n_descriptors = 5\n",
    "\n",
    "descriptors = np.random.normal(loc=0, scale=1, size=(n_compounds, n_descriptors))\n",
    "activity = 2 * descriptors[:, 0] - descriptors[:, 1] + 0.5 * descriptors[:, 2] + np.random.normal(0, 0.1, n_compounds)\n",
    "\n",
    "# Calculate Pearson correlations\n",
    "correlations = np.array([stats.pearsonr(descriptors[:, i], activity)[0] for i in range(n_descriptors)])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(np.corrcoef(descriptors.T), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Descriptors')\n",
    "plt.xlabel('Descriptor Index')\n",
    "plt.ylabel('Descriptor Index')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(range(n_descriptors), correlations)\n",
    "plt.title('Descriptor-Activity Correlations')\n",
    "plt.xlabel('Descriptor Index')\n",
    "plt.ylabel('Pearson Correlation Coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify most correlated descriptor\n",
    "top_descriptor = np.argmax(np.abs(correlations))\n",
    "print(f\"Most correlated descriptor: {top_descriptor}\")\n",
    "print(f\"Correlation with activity: {correlations[top_descriptor]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80148b99-1f12-4d0b-b12d-41692a7855d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Protein Sequence Similarity Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cafcc-8a20-4162-afc5-fe411e63e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def generate_sequence(length):\n",
    "    return ''.join(np.random.choice(['A', 'C', 'G', 'T'], size=length))\n",
    "\n",
    "def sequence_to_vector(sequence):\n",
    "    return np.array([sequence.count(base) for base in 'ACGT']) / len(sequence)\n",
    "\n",
    "# Generate synthetic protein sequences\n",
    "n_sequences = 50\n",
    "seq_length = 1000\n",
    "sequences = [generate_sequence(seq_length) for _ in range(n_sequences)]\n",
    "\n",
    "# Convert sequences to numerical vectors\n",
    "seq_vectors = np.array([sequence_to_vector(seq) for seq in sequences])\n",
    "\n",
    "# Calculate Pearson correlation matrix\n",
    "corr_matrix = np.corrcoef(seq_vectors)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm')\n",
    "plt.title('Sequence Similarity Matrix')\n",
    "plt.xlabel('Sequence Index')\n",
    "plt.ylabel('Sequence Index')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(corr_matrix[np.triu_indices(n_sequences, k=1)], bins=20)\n",
    "plt.title('Distribution of Pairwise Correlations')\n",
    "plt.xlabel('Pearson Correlation Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most similar pair of sequences\n",
    "i, j = np.unravel_index(np.argmax(corr_matrix - np.eye(n_sequences)), corr_matrix.shape)\n",
    "print(f\"Most similar sequences: {i} and {j}\")\n",
    "print(f\"Their correlation: {corr_matrix[i, j]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1dbe4-e781-4185-a55b-eb0ea7d0210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drug Combination Synergy Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d248b8-3097-4089-a663-768e5c1d0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Generate synthetic dose-response data for two drugs and their combination\n",
    "doses = np.logspace(-2, 2, 20)\n",
    "response_drug1 = 100 / (1 + np.exp(-(np.log10(doses) - 1)))\n",
    "response_drug2 = 100 / (1 + np.exp(-(np.log10(doses) - 0.5)))\n",
    "response_combo = np.maximum(response_drug1, response_drug2) + np.random.normal(0, 5, 20)\n",
    "\n",
    "# Calculate Pearson correlations\n",
    "corr_drug1_combo = stats.pearsonr(response_drug1, response_combo)[0]\n",
    "corr_drug2_combo = stats.pearsonr(response_drug2, response_combo)[0]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.semilogx(doses, response_drug1, 'b-', label='Drug 1')\n",
    "plt.semilogx(doses, response_drug2, 'g-', label='Drug 2')\n",
    "plt.semilogx(doses, response_combo, 'r-', label='Combination')\n",
    "plt.title('Dose-Response Curves')\n",
    "plt.xlabel('Dose')\n",
    "plt.ylabel('Response')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(response_drug1, response_combo, label=f'Drug 1 (r={corr_drug1_combo:.2f})')\n",
    "plt.scatter(response_drug2, response_combo, label=f'Drug 2 (r={corr_drug2_combo:.2f})')\n",
    "plt.plot([0, 100], [0, 100], 'k--')\n",
    "plt.title('Individual Drug vs Combination Responses')\n",
    "plt.xlabel('Individual Drug Response')\n",
    "plt.ylabel('Combination Response')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Correlation between Drug 1 and Combination: {corr_drug1_combo:.2f}\")\n",
    "print(f\"Correlation between Drug 2 and Combination: {corr_drug2_combo:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b84b12-7acc-48ee-9162-d5ae8a35bef8",
   "metadata": {},
   "source": [
    "## Instances where we use the Hotelling's T-squared Statistic Equation: T^2 = n(x̄ - μ)^T S^-1 (x̄ - μ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6f81b-9c08-45b3-991a-03c1d3f05cab",
   "metadata": {},
   "source": [
    "The following examples demonstrate the importance of Hotelling's T-squared Statistic in various aspects of protein quality scoring and drug discovery.  They provide a multivariate measure of how much a sample deviates from an expected mean, allow for the detection of outliers or unusual samples in high-dimensional data, they can be used to compare groups of samples and detect global differences, account for correlations between variables, providing a more comprehensive assessment than univariate methods and finally they can be used in quality control processes to identify samples that deviate from expected norms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c0c37-4772-4c31-8a59-1f6c1a8dfd34",
   "metadata": {},
   "source": [
    "* **Protein Structure Quality Control:**  This example simulates protein structure quality metrics (resolution, R-free, and clashscore) and uses Hotelling's T-squared statistic to identify structures that significantly deviate from the expected quality. It visualizes the T-squared values for each structure and highlights those exceeding a critical value. This approach is useful for multivariate quality control in protein structure determination.\n",
    "\n",
    "* **Drug Discovery: Compound Screening:**  This example simulates compound properties and uses Hotelling's T-squared statistic to identify outlier compounds that deviate significantly from the expected property profile. It visualizes the compounds in a 2D PCA space, colored by their T-squared values. This approach is useful for identifying potentially interesting compounds in high-throughput screening.\n",
    "\n",
    "* **Protein-Ligand Binding Site Analysis**:  This example simulates binding site properties and uses Hotelling's T-squared statistic to identify unusual binding sites that deviate from the expected property profile. It visualizes the binding sites in 3D space, colored by their T-squared values. This approach is useful for identifying potentially interesting binding sites for drug design.\n",
    "\n",
    "* **Gene Expression Analysis in Drug Response**:  This example simulates gene expression data for control and treated samples, then uses Hotelling's T-squared statistic to assess the overall difference in gene expression profiles. It visualizes the distribution of T-squared values for both groups. This approach is useful for detecting global changes in gene expression in response to drug treatment.\n",
    "\n",
    "* **Protein Stability Analysis**:  TThis example simulates protein stability metrics for various mutations and uses Hotelling's T-squared statistic to identify mutations that significantly affect protein stability. It visualizes the T-squared values for each mutation and highlights those exceeding a critical value. This approach is useful for assessing the impact of mutations on overall protein stability in protein engineering and drug target analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a04a201-aa66-467c-a195-536f92d5fd07",
   "metadata": {},
   "source": [
    "Protein Structure Quality Control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9c84f-f100-4212-9dde-c70f4a674df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def hotelling_t2(x, mu, S_inv):\n",
    "    diff = x - mu\n",
    "    return diff.T @ S_inv @ diff\n",
    "\n",
    "# Generate synthetic protein quality metrics\n",
    "n_structures = 100\n",
    "n_metrics = 3\n",
    "mu = np.array([2.0, 0.2, 10.0])  # Expected values for resolution, R-free, and clashscore\n",
    "sigma = np.array([[0.1, 0.01, 0.5],\n",
    "                  [0.01, 0.001, 0.05],\n",
    "                  [0.5, 0.05, 4.0]])\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.multivariate_normal(mu, sigma, n_structures)\n",
    "\n",
    "# Calculate the inverse of the covariance matrix once\n",
    "S_inv = np.linalg.inv(np.cov(X.T))\n",
    "\n",
    "# Calculate Hotelling's T-squared statistic for each structure\n",
    "t2_values = np.array([hotelling_t2(X[i], mu, S_inv) for i in range(n_structures)])\n",
    "\n",
    "# Calculate critical value\n",
    "critical_value = stats.f.ppf(0.95, n_metrics, n_structures - n_metrics) * \\\n",
    "                 (n_metrics * (n_structures - 1) / (n_structures - n_metrics))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = plt.scatter(range(n_structures), t2_values, c=t2_values, cmap='viridis')\n",
    "plt.axhline(y=critical_value, color='r', linestyle='--', label='Critical Value')\n",
    "plt.colorbar(scatter, label=\"T-squared Value\")\n",
    "plt.title(\"Hotelling's T-squared Control Chart for Protein Structures\")\n",
    "plt.xlabel(\"Structure Index\")\n",
    "plt.ylabel(\"T-squared Statistic\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Identify out-of-control structures\n",
    "out_of_control = np.where(t2_values > critical_value)[0]\n",
    "print(f\"Number of out-of-control structures: {len(out_of_control)}\")\n",
    "print(f\"Indices of out-of-control structures: {out_of_control}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768fd08d-fdb6-4085-af35-af4d8fdea3a0",
   "metadata": {},
   "source": [
    "Drug Discovery: Compound Screening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded84ce-d7e9-472e-acf7-45bff440be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def hotelling_t2(x, mu, S_inv):\n",
    "    diff = x - mu\n",
    "    return diff.T @ S_inv @ diff\n",
    "\n",
    "# Generate synthetic compound properties\n",
    "n_compounds = 1000\n",
    "n_properties = 5\n",
    "mu = np.array([3.0, 2.5, 1.5, 4.0, 3.5])  # Expected property values\n",
    "sigma = np.diag([0.5, 0.3, 0.2, 0.4, 0.3])\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.multivariate_normal(mu, sigma, n_compounds)\n",
    "\n",
    "# Add some outliers\n",
    "X[:10] += np.random.normal(3, 1, (10, n_properties))\n",
    "\n",
    "# Calculate the inverse of the covariance matrix once\n",
    "S_inv = np.linalg.inv(np.cov(X.T))\n",
    "\n",
    "# Calculate Hotelling's T-squared statistic for each compound\n",
    "t2_values = np.array([hotelling_t2(X[i], mu, S_inv) for i in range(n_compounds)])\n",
    "\n",
    "# Calculate critical value\n",
    "critical_value = stats.f.ppf(0.99, n_properties, n_compounds - n_properties) * \\\n",
    "                 (n_properties * (n_compounds - 1) / (n_compounds - n_properties))\n",
    "\n",
    "# Perform PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=t2_values, cmap='viridis')\n",
    "plt.colorbar(scatter, label=\"T-squared Value\")\n",
    "plt.title(\"Compound Screening using Hotelling's T-squared Statistic\")\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.show()\n",
    "\n",
    "# Identify outlier compounds\n",
    "outliers = np.where(t2_values > critical_value)[0]\n",
    "print(f\"Number of outlier compounds: {len(outliers)}\")\n",
    "print(f\"Indices of outlier compounds: {outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00196d28-be15-43cb-9e51-fb14cf5e0270",
   "metadata": {},
   "source": [
    "Protein-Ligand Binding Site Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535155ec-39b5-4315-83e5-5769fdd95b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def hotelling_t2(x, mu, S_inv):\n",
    "    diff = x - mu\n",
    "    return diff.T @ S_inv @ diff\n",
    "\n",
    "# Generate synthetic binding site properties\n",
    "n_sites = 200\n",
    "n_properties = 3  # e.g., size, hydrophobicity, charge\n",
    "mu = np.array([10.0, 0.5, -1.0])  # Expected property values\n",
    "sigma = np.array([[1.0, 0.1, -0.2],\n",
    "                  [0.1, 0.05, 0.0],\n",
    "                  [-0.2, 0.0, 0.3]])\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.multivariate_normal(mu, sigma, n_sites)\n",
    "\n",
    "# Calculate the inverse of the covariance matrix once\n",
    "S_inv = np.linalg.inv(np.cov(X.T))\n",
    "\n",
    "# Calculate Hotelling's T-squared statistic for each binding site\n",
    "t2_values = np.array([hotelling_t2(X[i], mu, S_inv) for i in range(n_sites)])\n",
    "\n",
    "# Calculate critical value\n",
    "critical_value = stats.f.ppf(0.95, n_properties, n_sites - n_properties) * \\\n",
    "                 (n_properties * (n_sites - 1) / (n_sites - n_properties))\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=t2_values, cmap='viridis')\n",
    "ax.set_xlabel('Size')\n",
    "ax.set_ylabel('Hydrophobicity')\n",
    "ax.set_zlabel('Charge')\n",
    "plt.colorbar(scatter, label=\"T-squared Value\")\n",
    "plt.title(\"Binding Site Analysis using Hotelling's T-squared Statistic\")\n",
    "plt.show()\n",
    "\n",
    "# Identify unusual binding sites\n",
    "unusual_sites = np.where(t2_values > critical_value)[0]\n",
    "print(f\"Number of unusual binding sites: {len(unusual_sites)}\")\n",
    "print(f\"Indices of unusual binding sites: {unusual_sites}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a613b-b65e-4b14-8790-a7c981588426",
   "metadata": {},
   "source": [
    "Gene Expression Analysis in Drug Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b0066-c738-47c0-a975-292f4d00dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "def hotelling_t2(x, mu, S_inv):\n",
    "    diff = x - mu\n",
    "    return diff.T @ S_inv @ diff\n",
    "\n",
    "# Generate synthetic gene expression data\n",
    "n_samples = 100\n",
    "n_genes = 5\n",
    "mu_control = np.zeros(n_genes)\n",
    "mu_treated = np.array([0.5, -0.3, 0.8, -0.2, 0.4])\n",
    "sigma = np.eye(n_genes) * 0.1\n",
    "\n",
    "np.random.seed(42)\n",
    "X_control = np.random.multivariate_normal(mu_control, sigma, n_samples)\n",
    "X_treated = np.random.multivariate_normal(mu_treated, sigma, n_samples)\n",
    "\n",
    "# Calculate inverse covariance matrices\n",
    "S_inv_control = np.linalg.inv(np.cov(X_control.T))\n",
    "S_inv_treated = np.linalg.inv(np.cov(X_treated.T))\n",
    "\n",
    "# Calculate Hotelling's T-squared statistic for each sample\n",
    "t2_control = np.array([hotelling_t2(X_control[i], mu_control, S_inv_control) for i in range(n_samples)])\n",
    "t2_treated = np.array([hotelling_t2(X_treated[i], mu_treated, S_inv_treated) for i in range(n_samples)])\n",
    "\n",
    "# Calculate critical value\n",
    "critical_value = stats.f.ppf(0.95, n_genes, n_samples - n_genes) * \\\n",
    "                 (n_genes * (n_samples - 1) / (n_samples - n_genes))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(t2_control, shade=True, label='Control')\n",
    "sns.kdeplot(t2_treated, shade=True, label='Treated')\n",
    "plt.axvline(x=critical_value, color='r', linestyle='--', label='Critical Value')\n",
    "plt.title(\"Distribution of Hotelling's T-squared Statistic in Gene Expression Analysis\")\n",
    "plt.xlabel(\"T-squared Statistic\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compare average T-squared values\n",
    "print(f\"Average T-squared for control group: {np.mean(t2_control):.2f}\")\n",
    "print(f\"Average T-squared for treated group: {np.mean(t2_treated):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b95bc-42f6-4f21-b303-4374fff0a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Protein Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df6f3e-e64f-44dc-8d52-9875054bfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def hotelling_t2(x, mu, S_inv):\n",
    "    diff = x - mu\n",
    "    return diff.T @ S_inv @ diff\n",
    "\n",
    "# Generate synthetic protein stability data\n",
    "n_mutations = 100\n",
    "n_metrics = 3  # e.g., melting temperature, aggregation propensity, solubility\n",
    "mu_wildtype = np.array([60.0, 0.2, 0.8])  # Expected values for wild-type protein\n",
    "sigma = np.array([[4.0, -0.1, 0.2],\n",
    "                  [-0.1, 0.01, -0.01],\n",
    "                  [0.2, -0.01, 0.04]])\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.multivariate_normal(mu_wildtype, sigma, n_mutations)\n",
    "\n",
    "# Calculate the inverse of the covariance matrix once\n",
    "S_inv = np.linalg.inv(sigma)\n",
    "\n",
    "# Calculate Hotelling's T-squared statistic for each mutation\n",
    "t2_values = np.array([hotelling_t2(X[i], mu_wildtype, S_inv) for i in range(n_mutations)])\n",
    "\n",
    "# Calculate critical value\n",
    "critical_value = stats.f.ppf(0.95, n_metrics, n_mutations - n_metrics) * \\\n",
    "                 (n_metrics * (n_mutations - 1) / (n_mutations - n_metrics))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = plt.scatter(range(n_mutations), t2_values, c=t2_values, cmap='viridis')\n",
    "plt.axhline(y=critical_value, color='r', linestyle='--', label='Critical Value')\n",
    "plt.colorbar(scatter, label=\"T-squared Value\")\n",
    "plt.title(\"Protein Stability Analysis using Hotelling's T-squared Statistic\")\n",
    "plt.xlabel(\"Mutation Index\")\n",
    "plt.ylabel(\"T-squared Statistic\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Identify significant mutations\n",
    "significant_mutations = np.where(t2_values > critical_value)[0]\n",
    "print(f\"Number of significant mutations: {len(significant_mutations)}\")\n",
    "print(f\"Indices of significant mutations: {significant_mutations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566f4c1-4267-4475-9cbe-14c8a5c94938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1962b1f-239a-4d95-b8ec-8c38b3619625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
