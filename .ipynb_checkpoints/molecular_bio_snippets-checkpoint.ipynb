{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear transformations and equations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each of these examples, the linear transformation serves as a fundamental building block that can be part of more complex models or analyses. In practice, these transformations are often combined with non-linear activations and other layers in deep learning models for improved performance and capability to capture complex relationships in biological data. Remember that while these linear transformations are useful, many biological processes are inherently non-linear. Therefore, these linear models are often used as components within more complex, non-linear models (like neural networks) in advanced bioinformatics applications.\n",
    "\n",
    "I have put together some of these equations together with some viualizations and code snippets in Python.\n",
    "\n",
    "These visualizations provide different ways to interpret the data and results:\n",
    "\n",
    "Histograms show the distribution of predicted scores or values.\n",
    "Heatmaps visualize 2D data, useful for showing relationships between features or samples.\n",
    "Box plots display the distribution of values across different categories or groups.\n",
    "Scatter plots can reveal relationships or clusters between two variables.\n",
    "\n",
    "Remember to adjust the figure sizes, color schemes, and other parameters as needed to best represent your specific data. These visualizations can be very helpful in understanding the patterns in your data and the outputs of your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances where we the Position-Specific Scoring Matrix (PSSM) Equation:   S = Σ(i=1 to L) log(P_i / B_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcription Factor Binding Site Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def pssm_score(sequence, pssm, background_probs):\n",
    "    score = 0\n",
    "    pseudo_count = 1e-10  # Small pseudo-count to avoid log(0)\n",
    "    for i, nucleotide in enumerate(sequence):\n",
    "        p = pssm[nucleotide][i] + pseudo_count\n",
    "        b = background_probs[nucleotide] + pseudo_count\n",
    "        score += np.log2(p / b)\n",
    "    return score\n",
    "\n",
    "# Example PSSM for a transcription factor binding site\n",
    "pssm = {\n",
    "    'A': [0.1, 0.6, 0.1, 0.1, 0.9],\n",
    "    'C': [0.1, 0.1, 0.1, 0.8, 0.0],\n",
    "    'G': [0.7, 0.1, 0.1, 0.0, 0.1],\n",
    "    'T': [0.1, 0.2, 0.7, 0.1, 0.0]\n",
    "}\n",
    "\n",
    "background_probs = {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "\n",
    "# Generate random DNA sequences\n",
    "sequences = [''.join(np.random.choice(['A', 'C', 'G', 'T'], 5)) for _ in range(1000)]\n",
    "\n",
    "scores = [pssm_score(seq, pssm, background_probs) for seq in sequences]\n",
    "\n",
    "# Filter out any remaining -inf values (should be rare or none with pseudo-count)\n",
    "scores = [score for score in scores if np.isfinite(score)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(scores, bins=30, edgecolor='black')\n",
    "plt.title('Distribution of PSSM Scores for Random Sequences')\n",
    "plt.xlabel('PSSM Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualize PSSM\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pd.DataFrame(pssm), annot=True, cmap='YlGnBu')\n",
    "plt.title('Position-Specific Scoring Matrix (PSSM)')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Nucleotide')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Family Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def generate_pssm(sequences):\n",
    "    length = len(sequences[0])\n",
    "    pssm = np.zeros((length, 20))\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    for i in range(length):\n",
    "        for j, aa in enumerate(amino_acids):\n",
    "            pssm[i, j] = sum(seq[i] == aa for seq in sequences) / len(sequences)\n",
    "    return pssm\n",
    "\n",
    "def pssm_score(sequence, pssm, background_probs):\n",
    "    score = 0\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in amino_acids:\n",
    "            j = amino_acids.index(aa)\n",
    "            score += np.log2(pssm[i, j] / background_probs[aa])\n",
    "    return score\n",
    "\n",
    "# Generate synthetic data\n",
    "def generate_family(length, num_sequences):\n",
    "    consensus = ''.join(np.random.choice(list('ACDEFGHIKLMNPQRSTVWY'), length))\n",
    "    sequences = []\n",
    "    for _ in range(num_sequences):\n",
    "        seq = ''.join(np.random.choice([aa, np.random.choice(list('ACDEFGHIKLMNPQRSTVWY'))] \n",
    "                                       , p=[0.9, 0.1]) for aa in consensus)\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "family1 = generate_family(50, 100)\n",
    "family2 = generate_family(50, 100)\n",
    "\n",
    "# Create PSSMs\n",
    "pssm1 = generate_pssm(family1)\n",
    "pssm2 = generate_pssm(family2)\n",
    "\n",
    "background_probs = {aa: 0.05 for aa in 'ACDEFGHIKLMNPQRSTVWY'}\n",
    "\n",
    "# Score sequences\n",
    "X = family1 + family2\n",
    "y = [0] * len(family1) + [1] * len(family2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Simple classifier\n",
    "def classify(sequence):\n",
    "    score1 = pssm_score(sequence, pssm1, background_probs)\n",
    "    score2 = pssm_score(sequence, pssm2, background_probs)\n",
    "    return 0 if score1 > score2 else 1\n",
    "\n",
    "y_pred = [classify(seq) for seq in X_test]\n",
    "\n",
    "# Visualize results\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Family 1', 'Family 2'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix for Protein Family Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Sequence Alignment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def generate_pssm(alignment):\n",
    "    length = len(alignment[0])\n",
    "    pssm = np.zeros((length, 20))\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    for i in range(length):\n",
    "        for j, aa in enumerate(amino_acids):\n",
    "            pssm[i, j] = sum(seq[i] == aa for seq in alignment) / len(alignment)\n",
    "    return pssm\n",
    "\n",
    "def pssm_score(sequence, pssm, background_probs):\n",
    "    score = 0\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in amino_acids:\n",
    "            j = amino_acids.index(aa)\n",
    "            score += np.log2(pssm[i, j] / background_probs[aa])\n",
    "    return score\n",
    "\n",
    "# Generate a mock multiple sequence alignment\n",
    "alignment = [\n",
    "    \"MAEEPQSDPSVEPPLSQETFSDLWKLLPENNVLSPLPSQAMDDLMLSPDDIEQWFTEDPGP\",\n",
    "    \"MEEPQSDPSVEPPLSQETFSDLWKLLPPNNVLSTLPSSDSIEELFLSENVAGWLEDPDEAP\",\n",
    "    \"MEEPQSDLSEEPPLSQETFSDLWNLLPENKLLDLPLSPEDIEQWLSEDPGPDEAPRMPEAA\",\n",
    "    \"MEEPQSDLSIELPLSQETFSGLWKLLPPEDILPSPHCMDDLLLPQDVEEFFEGPSEALRVS\"\n",
    "]\n",
    "\n",
    "pssm = generate_pssm(alignment)\n",
    "background_probs = {aa: 0.05 for aa in 'ACDEFGHIKLMNPQRSTVWY'}\n",
    "\n",
    "# Score each sequence in the alignment\n",
    "scores = [pssm_score(seq, pssm, background_probs) for seq in alignment]\n",
    "\n",
    "# Visualize PSSM\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(pssm, cmap='YlGnBu', xticklabels=list('ACDEFGHIKLMNPQRSTVWY'))\n",
    "plt.title('Position-Specific Scoring Matrix (PSSM) for Multiple Sequence Alignment')\n",
    "plt.xlabel('Amino Acid')\n",
    "plt.ylabel('Position')\n",
    "plt.show()\n",
    "\n",
    "# Visualize scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(scores)), scores)\n",
    "plt.title('PSSM Scores for Sequences in Multiple Sequence Alignment')\n",
    "plt.xlabel('Sequence Index')\n",
    "plt.ylabel('PSSM Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def generate_pssm(motifs):\n",
    "    length = len(motifs[0])\n",
    "    pssm = np.zeros((length, 4))\n",
    "    nucleotides = 'ACGT'\n",
    "    for i in range(length):\n",
    "        for j, nt in enumerate(nucleotides):\n",
    "            pssm[i, j] = sum(seq[i] == nt for seq in motifs) / len(motifs)\n",
    "    return pssm\n",
    "\n",
    "def pssm_score(sequence, pssm, background_probs):\n",
    "    score = 0\n",
    "    nucleotides = 'ACGT'\n",
    "    for i, nt in enumerate(sequence):\n",
    "        j = nucleotides.index(nt)\n",
    "        if pssm[i, j] > 0:\n",
    "            score += np.log2(pssm[i, j] / background_probs[nt])\n",
    "        else:\n",
    "            score += np.log2(1e-300 / background_probs[nt])  # Very low score for zero probability\n",
    "    return score\n",
    "\n",
    "def generate_sequences_with_motif(num_sequences, seq_length, motif):\n",
    "    sequences = []\n",
    "    for _ in range(num_sequences):\n",
    "        seq = ''.join(np.random.choice(['A', 'C', 'G', 'T']) for _ in range(seq_length))\n",
    "        start = np.random.randint(0, seq_length - len(motif) + 1)\n",
    "        seq = seq[:start] + motif + seq[start+len(motif):]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "def scan_sequence(sequence, pssm, background_probs, window_size):\n",
    "    scores = []\n",
    "    for i in range(len(sequence) - window_size + 1):\n",
    "        subseq = sequence[i:i+window_size]\n",
    "        scores.append(pssm_score(subseq, pssm, background_probs))\n",
    "    return scores\n",
    "\n",
    "motif = \"ATGCATGC\"\n",
    "sequences = generate_sequences_with_motif(100, 50, motif)\n",
    "\n",
    "pssm = generate_pssm([motif])\n",
    "background_probs = {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "\n",
    "all_scores = []\n",
    "for seq in sequences:\n",
    "    scores = scan_sequence(seq, pssm, background_probs, len(motif))\n",
    "    all_scores.extend(scores)\n",
    "\n",
    "# Visualize PSSM\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pssm, annot=True, cmap='YlGnBu', xticklabels=['A', 'C', 'G', 'T'])\n",
    "plt.title('Position-Specific Scoring Matrix (PSSM) for Motif')\n",
    "plt.xlabel('Nucleotide')\n",
    "plt.ylabel('Position')\n",
    "plt.show()\n",
    "\n",
    "# Visualize score distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_scores, bins=50, edgecolor='black')\n",
    "plt.title('Distribution of PSSM Scores for Sequence Windows')\n",
    "plt.xlabel('PSSM Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Secondary Structure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def generate_pssm(sequences, structures):\n",
    "    length = len(sequences[0])\n",
    "    pssm = np.zeros((length, 20, 3))  # 20 amino acids, 3 structure types\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    structure_types = 'HEC'  # Helix, Sheet (Extended), Coil\n",
    "    for i in range(length):\n",
    "        for j, aa in enumerate(amino_acids):\n",
    "            for k, st in enumerate(structure_types):\n",
    "                count = sum((seq[i] == aa and struct[i] == st) for seq, struct in zip(sequences, structures))\n",
    "                total = sum(seq[i] == aa for seq in sequences)\n",
    "                pssm[i, j, k] = count / total if total > 0 else 0\n",
    "    return pssm\n",
    "\n",
    "def pssm_score(sequence, pssm, background_probs):\n",
    "    scores = np.zeros((len(sequence), 3))\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in amino_acids:\n",
    "            j = amino_acids.index(aa)\n",
    "            for k in range(3):\n",
    "                scores[i, k] = np.log2(pssm[i, j, k] / background_probs[aa])\n",
    "    return scores\n",
    "\n",
    "# Generate synthetic data\n",
    "def generate_data(num_sequences, length):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    structure_types = 'HEC'\n",
    "    sequences = [''.join(np.random.choice(list(amino_acids)) for _ in range(length)) for _ in range(num_sequences)]\n",
    "    structures = [''.join(np.random.choice(list(structure_types)) for _ in range(length)) for _ in range(num_sequences)]\n",
    "    return sequences, structures\n",
    "\n",
    "sequences, structures = generate_data(1000, 50)\n",
    "\n",
    "# Create PSSM\n",
    "pssm = generate_pssm(sequences, structures)\n",
    "background_probs = {aa: 0.05 for aa in 'ACDEFGHIKLMNPQRSTVWY'}\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, structures, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict secondary structure\n",
    "def predict_structure(sequence):\n",
    "    scores = pssm_score(sequence, pssm, background_probs)\n",
    "    return ''.join('HEC'[np.argmax(score)] for score in scores)\n",
    "\n",
    "y_pred = [predict_structure(seq) for seq in X_test]\n",
    "\n",
    "# Flatten predictions and true values\n",
    "y_test_flat = ''.join(y_test)\n",
    "y_pred_flat = ''.join(y_pred)\n",
    "\n",
    "# Visualize results\n",
    "cm = confusion_matrix(list(y_test_flat), list(y_pred_flat))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['H', 'E', 'C'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix for Secondary Structure Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Visualize PSSM for a specific position\n",
    "position = 25  # Choose a specific position to visualize\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pssm[position], annot=True, cmap='YlGnBu', \n",
    "            xticklabels=['H', 'E', 'C'], \n",
    "            yticklabels=list('ACDEFGHIKLMNPQRSTVWY'))\n",
    "plt.title(f'PSSM for Position {position} in Secondary Structure Prediction')\n",
    "plt.xlabel('Secondary Structure')\n",
    "plt.ylabel('Amino Acid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances where we use:     y = x · A^T + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene expression analysis: Transforming gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Simulated gene expression data\n",
    "num_samples = 100\n",
    "num_genes = 1000\n",
    "gene_expression = torch.randn(num_samples, num_genes)\n",
    "\n",
    "# Linear transformation for gene expression analysis\n",
    "output_dim = 50\n",
    "A = torch.randn(output_dim, num_genes)\n",
    "b = torch.randn(output_dim)\n",
    "\n",
    "# Transform gene expression data\n",
    "transformed_expression = torch.matmul(gene_expression, A.t()) + b\n",
    "\n",
    "print(\"Original shape:\", gene_expression.shape)\n",
    "print(\"Transformed shape:\", transformed_expression.shape)\n",
    "\n",
    "# Example analysis: Find genes with highest average expression\n",
    "avg_expression = torch.mean(transformed_expression, dim=0)\n",
    "top_genes = torch.argsort(avg_expression, descending=True)[:10]\n",
    "print(\"Top 10 gene indices after transformation:\", top_genes.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Structure Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Simulated protein features (e.g., amino acid properties)\n",
    "num_residues = 200\n",
    "feature_dim = 20\n",
    "protein_features = torch.randn(1, num_residues, feature_dim)\n",
    "\n",
    "# Linear transformation for structure prediction\n",
    "output_dim = 3  # 3D coordinates\n",
    "A = torch.randn(output_dim, feature_dim)\n",
    "b = torch.randn(output_dim)\n",
    "\n",
    "# Predict 3D coordinates\n",
    "predicted_structure = torch.matmul(protein_features, A.t()) + b\n",
    "\n",
    "print(\"Protein features shape:\", protein_features.shape)\n",
    "print(\"Predicted structure shape:\", predicted_structure.shape)\n",
    "\n",
    "# Visualize first few predicted coordinates\n",
    "print(\"First 5 predicted 3D coordinates:\")\n",
    "print(predicted_structure[0, :5, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Analysis (DNA encoding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# DNA sequence\n",
    "dna_seq = \"ATCGATCGATCG\"\n",
    "\n",
    "# One-hot encoding\n",
    "nucleotide_to_index = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "one_hot = torch.zeros(len(dna_seq), 4)\n",
    "for i, nucleotide in enumerate(dna_seq):\n",
    "    one_hot[i, nucleotide_to_index[nucleotide]] = 1\n",
    "\n",
    "# Linear transformation for sequence analysis\n",
    "output_dim = 8\n",
    "A = torch.randn(output_dim, 4)\n",
    "b = torch.randn(output_dim)\n",
    "\n",
    "# Transform encoded sequence\n",
    "transformed_seq = torch.matmul(one_hot, A.t()) + b\n",
    "\n",
    "print(\"One-hot encoded shape:\", one_hot.shape)\n",
    "print(\"Transformed sequence shape:\", transformed_seq.shape)\n",
    "\n",
    "# Example analysis: Find position with highest transformed value\n",
    "max_pos = torch.argmax(torch.max(transformed_seq, dim=1)[0])\n",
    "print(\"Position with highest transformed value:\", max_pos.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of what happens during dimensionality reduction:\n",
    "\n",
    "Original Data:\n",
    "\n",
    "We start with high-dimensional data (100 dimensions in this case).\n",
    "Each data point is represented by 100 features, which is difficult to visualize directly.\n",
    "The first plot shows only the first 3 dimensions of this 100-dimensional space.\n",
    "\n",
    "\n",
    "Dimensionality Reduction:\n",
    "\n",
    "We reduce the 100-dimensional data to 2 dimensions.\n",
    "This process attempts to preserve the most important information or patterns in the data.\n",
    "\n",
    "\n",
    "Our Linear Transformation Method:\n",
    "\n",
    "We use the equation y = x · A^T + b to transform the data.\n",
    "This method projects the high-dimensional data onto a 2D plane.\n",
    "The resulting plot shows how the data points are distributed in this new 2D space.\n",
    "However, this random linear transformation may not optimally preserve the data structure.\n",
    "\n",
    "\n",
    "PCA (Principal Component Analysis) Method:\n",
    "\n",
    "PCA finds the directions (principal components) of maximum variance in the data.\n",
    "It then projects the data onto these principal components.\n",
    "The resulting plot shows the data distributed along the two most significant principal components.\n",
    "PCA is often more effective at preserving the overall structure of the data.\n",
    "\n",
    "We added plt.ion() at the beginning to enable interactive mode. We removed the plt.savefig() calls and kept the plt.show() calls. We added plt.ioff() and a final plt.show() at the end to keep the plot windows open.\n",
    "\n",
    "When you run this script in PyCharm:\n",
    "\n",
    "The plots should appear in the \"SciView\" tool window (usually on the right side of the PyCharm window).\n",
    "If the plots don't appear automatically, you might need to click on the \"Python Scientific\" tab in the tool window.\n",
    "You can interact with the plots, zoom in/out, and pan around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Enable interactive mode for matplotlib\n",
    "plt.ion()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulated high-dimensional biological data\n",
    "num_samples = 1000\n",
    "original_dim = 100\n",
    "data = torch.randn(num_samples, original_dim)\n",
    "\n",
    "# Linear transformation for dimensionality reduction\n",
    "reduced_dim = 2\n",
    "A = torch.randn(reduced_dim, original_dim)\n",
    "b = torch.randn(reduced_dim)\n",
    "\n",
    "# Reduce dimensionality using our linear transformation\n",
    "reduced_data = torch.matmul(data, A.t()) + b\n",
    "\n",
    "print(\"Original data shape:\", data.shape)\n",
    "print(\"Reduced data shape:\", reduced_data.shape)\n",
    "\n",
    "# Use PCA for comparison\n",
    "pca = PCA(n_components=2)\n",
    "pca_reduced_data = pca.fit_transform(data.numpy())\n",
    "\n",
    "# Plot 1: Original vs Our Method\n",
    "fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Original data (first 2 dimensions)\n",
    "ax1.scatter(data[:, 0].numpy(), data[:, 1].numpy(), alpha=0.5)\n",
    "ax1.set_title(\"Original Data (First 2 Dimensions)\")\n",
    "ax1.set_xlabel(\"Dimension 1\")\n",
    "ax1.set_ylabel(\"Dimension 2\")\n",
    "\n",
    "# Reduced data (our method)\n",
    "ax2.scatter(reduced_data[:, 0].numpy(), reduced_data[:, 1].numpy(), alpha=0.5)\n",
    "ax2.set_title(\"Reduced Data (Our Method)\")\n",
    "ax2.set_xlabel(\"Dimension 1\")\n",
    "ax2.set_ylabel(\"Dimension 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Original vs PCA\n",
    "fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Original data (first 2 dimensions)\n",
    "ax1.scatter(data[:, 0].numpy(), data[:, 1].numpy(), alpha=0.5)\n",
    "ax1.set_title(\"Original Data (First 2 Dimensions)\")\n",
    "ax1.set_xlabel(\"Dimension 1\")\n",
    "ax1.set_ylabel(\"Dimension 2\")\n",
    "\n",
    "# Reduced data (PCA)\n",
    "ax2.scatter(pca_reduced_data[:, 0], pca_reduced_data[:, 1], alpha=0.5)\n",
    "ax2.set_title(\"Reduced Data (PCA)\")\n",
    "ax2.set_xlabel(\"Principal Component 1\")\n",
    "ax2.set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance ratio (PCA):\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Keep the plot windows open\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein-Protein Interaction Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This could be used as part of a larger model to predict protein-protein interactions based on protein features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Protein features (e.g., amino acid composition, hydrophobicity, etc.)\n",
    "protein_features = torch.randn(100, 50)  # 100 proteins, 50 features each\n",
    "\n",
    "# Linear transformation for interaction prediction\n",
    "A = torch.randn(1, 50)\n",
    "b = torch.randn(1)\n",
    "\n",
    "# Predict interaction scores\n",
    "interaction_scores = torch.matmul(protein_features, A.t()) + b\n",
    "\n",
    "# Visualize interaction scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(interaction_scores.numpy(), bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Protein-Protein Interaction Scores')\n",
    "plt.xlabel('Interaction Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap of protein features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(protein_features.numpy(), aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Feature Value')\n",
    "plt.title('Heatmap of Protein Features')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Protein Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic Variant Effect Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This could be used to predict the functional impact of genomic variants on different cellular processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Genomic variant features (e.g., position, surrounding sequence properties)\n",
    "variant_features = torch.randn(1000, 30)  # 1000 variants, 30 features each\n",
    "\n",
    "# Linear transformation for effect prediction\n",
    "A = torch.randn(5, 30)  # 5 different effect categories\n",
    "b = torch.randn(5)\n",
    "\n",
    "# Predict variant effects\n",
    "effect_predictions = torch.matmul(variant_features, A.t()) + b\n",
    "\n",
    "# Visualize effect predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(effect_predictions.numpy())\n",
    "plt.title('Distribution of Predicted Effects Across Categories')\n",
    "plt.xlabel('Effect Category')\n",
    "plt.ylabel('Predicted Effect Score')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of two effect categories\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(effect_predictions[:, 0], effect_predictions[:, 1], alpha=0.5)\n",
    "plt.title('Scatter Plot of Two Effect Categories')\n",
    "plt.xlabel('Effect Category 1')\n",
    "plt.ylabel('Effect Category 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Response Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This could be used to predict drug responses across different cell lines based on molecular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drug molecular features and cell line features\n",
    "drug_features = torch.randn(50, 100)  # 50 drugs, 100 features each\n",
    "cell_features = torch.randn(20, 50)   # 20 cell lines, 50 features each\n",
    "\n",
    "# Combine features\n",
    "combined_features = torch.cat([drug_features.unsqueeze(1).expand(-1, 20, -1),\n",
    "                               cell_features.unsqueeze(0).expand(50, -1, -1)], dim=2)\n",
    "\n",
    "# Linear transformation for response prediction\n",
    "A = torch.randn(1, 150)  # 100 drug features + 50 cell features\n",
    "b = torch.randn(1)\n",
    "\n",
    "# Predict drug response\n",
    "response_predictions = torch.matmul(combined_features.view(-1, 150), A.t()) + b\n",
    "response_predictions = response_predictions.view(50, 20)\n",
    "\n",
    "# Visualize drug response predictions as a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(response_predictions.numpy(), cmap='coolwarm', center=0)\n",
    "plt.title('Heatmap of Predicted Drug Responses')\n",
    "plt.xlabel('Cell Line Index')\n",
    "plt.ylabel('Drug Index')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of response predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(response_predictions.numpy().flatten(), bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Predicted Drug Responses')\n",
    "plt.xlabel('Predicted Response')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metabolic Pathway Flux Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This could be used to estimate reaction fluxes in metabolic pathways based on metabolite concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Metabolite concentrations\n",
    "metabolite_concentrations = torch.randn(100, 50)  # 100 samples, 50 metabolites\n",
    "\n",
    "# Linear transformation for flux prediction\n",
    "A = torch.randn(20, 50)  # 20 different reactions\n",
    "b = torch.randn(20)\n",
    "\n",
    "# Predict reaction fluxes\n",
    "predicted_fluxes = torch.matmul(metabolite_concentrations, A.t()) + b\n",
    "\n",
    "# Visualize predicted fluxes\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(predicted_fluxes.numpy())\n",
    "plt.title('Distribution of Predicted Fluxes Across Reactions')\n",
    "plt.xlabel('Reaction Index')\n",
    "plt.ylabel('Predicted Flux')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap of metabolite concentrations\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(metabolite_concentrations.numpy(), aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Concentration')\n",
    "plt.title('Heatmap of Metabolite Concentrations')\n",
    "plt.xlabel('Metabolite Index')\n",
    "plt.ylabel('Sample Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription Factor Binding Site Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This could be part of a model to predict transcription factor binding sites in DNA sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DNA sequence features (e.g., one-hot encoded)\n",
    "dna_sequences = torch.randn(1000, 100, 4)  # 1000 sequences, 100 bp length, 4 nucleotides\n",
    "\n",
    "# Linear transformation for binding prediction\n",
    "A = torch.randn(1, 400)  # Flattened filter\n",
    "b = torch.randn(1)\n",
    "\n",
    "# Predict binding scores\n",
    "binding_scores = torch.matmul(dna_sequences.view(1000, -1), A.t()) + b\n",
    "\n",
    "# Visualize binding scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(binding_scores.numpy(), bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Predicted Binding Scores')\n",
    "plt.xlabel('Binding Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualize a sample DNA sequence\n",
    "sample_sequence = dna_sequences[0].numpy().T\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(sample_sequence, aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Nucleotide Encoding')\n",
    "plt.title('Visualization of a Sample DNA Sequence')\n",
    "plt.xlabel('Position in Sequence')\n",
    "plt.ylabel('Nucleotide (A, T, C, G)')\n",
    "plt.yticks([0, 1, 2, 3], ['A', 'T', 'C', 'G'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
